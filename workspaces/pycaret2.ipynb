{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATASET_PATH = Path(\"../dataset/\")\n",
    "TRAIN_DATA_PATH = DATASET_PATH / \"train.csv\"\n",
    "TEST_DATA_PATH = DATASET_PATH / \"test.csv\"\n",
    "SUBMIT_DATA_PATH = DATASET_PATH / \"sample_submit.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import polars as pl\n",
    "import polars.selectors as cs\n",
    "import numpy as np\n",
    "\n",
    "train_df = pl.scan_csv(TRAIN_DATA_PATH)\n",
    "test_df = pl.scan_csv(TEST_DATA_PATH).with_columns(pl.lit(None).alias(\"blueWins\"))\n",
    "all_df = pl.concat([train_df, test_df]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.83 ms, sys: 5.47 ms, total: 8.3 ms\n",
      "Wall time: 2.16 ms\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 11)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>gameId</th><th>blueFirstBlood</th><th>blueKills</th><th>blueDeaths</th><th>blueAssists</th><th>blueEliteMonsters</th><th>blueDragons</th><th>blueTotalGold</th><th>blueTotalExperience</th><th>blueWins</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>8000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2000.0</td></tr><tr><td>&quot;mean&quot;</td><td>4999.5</td><td>0.5151</td><td>6.0654</td><td>5.9153</td><td>5.9401</td><td>0.5396</td><td>0.3584</td><td>17158.873</td><td>17987.413</td><td>0.49175</td></tr><tr><td>&quot;std&quot;</td><td>2886.89568</td><td>0.499797</td><td>2.631808</td><td>2.649232</td><td>3.207638</td><td>0.626954</td><td>0.479554</td><td>1824.773215</td><td>771.583455</td><td>0.499963</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>13475.0</td><td>16650.0</td><td>0.0</td></tr><tr><td>&quot;25%&quot;</td><td>2500.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>16544.0</td><td>17256.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>5000.0</td><td>1.0</td><td>6.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>17409.0</td><td>18021.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>7499.0</td><td>1.0</td><td>8.0</td><td>8.0</td><td>8.0</td><td>1.0</td><td>1.0</td><td>18274.0</td><td>18472.0</td><td>1.0</td></tr><tr><td>&quot;max&quot;</td><td>9999.0</td><td>1.0</td><td>14.0</td><td>14.0</td><td>17.0</td><td>2.0</td><td>1.0</td><td>20619.0</td><td>20101.0</td><td>1.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 11)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬───────────┬──────────┐\n",
       "│ describe  ┆ gameId    ┆ blueFirst ┆ blueKills ┆ … ┆ blueDrago ┆ blueTotal ┆ blueTotal ┆ blueWins │\n",
       "│ ---       ┆ ---       ┆ Blood     ┆ ---       ┆   ┆ ns        ┆ Gold      ┆ Experienc ┆ ---      │\n",
       "│ str       ┆ f64       ┆ ---       ┆ f64       ┆   ┆ ---       ┆ ---       ┆ e         ┆ f64      │\n",
       "│           ┆           ┆ f64       ┆           ┆   ┆ f64       ┆ f64       ┆ ---       ┆          │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆           ┆ f64       ┆          │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪═══════════╪══════════╡\n",
       "│ count     ┆ 10000.0   ┆ 10000.0   ┆ 10000.0   ┆ … ┆ 10000.0   ┆ 10000.0   ┆ 10000.0   ┆ 8000.0   │\n",
       "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ 2000.0   │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆           ┆          │\n",
       "│ mean      ┆ 4999.5    ┆ 0.5151    ┆ 6.0654    ┆ … ┆ 0.3584    ┆ 17158.873 ┆ 17987.413 ┆ 0.49175  │\n",
       "│ std       ┆ 2886.8956 ┆ 0.499797  ┆ 2.631808  ┆ … ┆ 0.479554  ┆ 1824.7732 ┆ 771.58345 ┆ 0.499963 │\n",
       "│           ┆ 8         ┆           ┆           ┆   ┆           ┆ 15        ┆ 5         ┆          │\n",
       "│ min       ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 13475.0   ┆ 16650.0   ┆ 0.0      │\n",
       "│ 25%       ┆ 2500.0    ┆ 0.0       ┆ 4.0       ┆ … ┆ 0.0       ┆ 16544.0   ┆ 17256.0   ┆ 0.0      │\n",
       "│ 50%       ┆ 5000.0    ┆ 1.0       ┆ 6.0       ┆ … ┆ 0.0       ┆ 17409.0   ┆ 18021.0   ┆ 0.0      │\n",
       "│ 75%       ┆ 7499.0    ┆ 1.0       ┆ 8.0       ┆ … ┆ 1.0       ┆ 18274.0   ┆ 18472.0   ┆ 1.0      │\n",
       "│ max       ┆ 9999.0    ┆ 1.0       ┆ 14.0      ┆ … ┆ 1.0       ┆ 20619.0   ┆ 20101.0   ┆ 1.0      │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴───────────┴──────────┘"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = (\n",
    "    all_df.lazy()\n",
    "    .with_columns(\n",
    "        (pl.col(\"blueEliteMonsters\") - pl.col(\"blueDragons\")).alias(\"blueHerald\"),\n",
    "        pl.col([\"blueTotalExperience\", \"blueTotalGold\"]).cast(pl.Float64),\n",
    "    )\n",
    "    .with_columns(\n",
    "        pl.when(pl.all().is_infinite()).then(9999).otherwise(pl.all()).name.keep()\n",
    "    )\n",
    "    .drop(cs.by_name([\"blueEliteMonsters\", \"blueAssists\"]))\n",
    "    # .filter(pl.col(\"blueHerald\") >= 0)\n",
    "    .collect()\n",
    ")\n",
    "\n",
    "train_df = all_df.filter(pl.col(\"blueWins\").is_not_null())\n",
    "test_df = all_df.filter(pl.col(\"blueWins\").is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (9, 10)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>describe</th><th>gameId</th><th>blueFirstBlood</th><th>blueKills</th><th>blueDeaths</th><th>blueDragons</th><th>blueTotalGold</th><th>blueTotalExperience</th><th>blueWins</th><th>blueHerald</th></tr><tr><td>str</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>&quot;count&quot;</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>10000.0</td><td>8000.0</td><td>10000.0</td></tr><tr><td>&quot;null_count&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>2000.0</td><td>0.0</td></tr><tr><td>&quot;mean&quot;</td><td>4999.5</td><td>0.5151</td><td>6.0654</td><td>5.9153</td><td>0.3584</td><td>17158.873</td><td>17987.413</td><td>0.49175</td><td>0.1812</td></tr><tr><td>&quot;std&quot;</td><td>2886.89568</td><td>0.499797</td><td>2.631808</td><td>2.649232</td><td>0.479554</td><td>1824.773215</td><td>771.583455</td><td>0.499963</td><td>0.389078</td></tr><tr><td>&quot;min&quot;</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>13475.0</td><td>16650.0</td><td>0.0</td><td>-1.0</td></tr><tr><td>&quot;25%&quot;</td><td>2500.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>16544.0</td><td>17256.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;50%&quot;</td><td>5000.0</td><td>1.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>17409.0</td><td>18021.0</td><td>0.0</td><td>0.0</td></tr><tr><td>&quot;75%&quot;</td><td>7499.0</td><td>1.0</td><td>8.0</td><td>8.0</td><td>1.0</td><td>18274.0</td><td>18472.0</td><td>1.0</td><td>0.0</td></tr><tr><td>&quot;max&quot;</td><td>9999.0</td><td>1.0</td><td>14.0</td><td>14.0</td><td>1.0</td><td>20619.0</td><td>20101.0</td><td>1.0</td><td>2.0</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (9, 10)\n",
       "┌───────────┬───────────┬───────────┬───────────┬───┬───────────┬───────────┬──────────┬───────────┐\n",
       "│ describe  ┆ gameId    ┆ blueFirst ┆ blueKills ┆ … ┆ blueTotal ┆ blueTotal ┆ blueWins ┆ blueHeral │\n",
       "│ ---       ┆ ---       ┆ Blood     ┆ ---       ┆   ┆ Gold      ┆ Experienc ┆ ---      ┆ d         │\n",
       "│ str       ┆ f64       ┆ ---       ┆ f64       ┆   ┆ ---       ┆ e         ┆ f64      ┆ ---       │\n",
       "│           ┆           ┆ f64       ┆           ┆   ┆ f64       ┆ ---       ┆          ┆ f64       │\n",
       "│           ┆           ┆           ┆           ┆   ┆           ┆ f64       ┆          ┆           │\n",
       "╞═══════════╪═══════════╪═══════════╪═══════════╪═══╪═══════════╪═══════════╪══════════╪═══════════╡\n",
       "│ count     ┆ 10000.0   ┆ 10000.0   ┆ 10000.0   ┆ … ┆ 10000.0   ┆ 10000.0   ┆ 8000.0   ┆ 10000.0   │\n",
       "│ null_coun ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 0.0       ┆ 0.0       ┆ 2000.0   ┆ 0.0       │\n",
       "│ t         ┆           ┆           ┆           ┆   ┆           ┆           ┆          ┆           │\n",
       "│ mean      ┆ 4999.5    ┆ 0.5151    ┆ 6.0654    ┆ … ┆ 17158.873 ┆ 17987.413 ┆ 0.49175  ┆ 0.1812    │\n",
       "│ std       ┆ 2886.8956 ┆ 0.499797  ┆ 2.631808  ┆ … ┆ 1824.7732 ┆ 771.58345 ┆ 0.499963 ┆ 0.389078  │\n",
       "│           ┆ 8         ┆           ┆           ┆   ┆ 15        ┆ 5         ┆          ┆           │\n",
       "│ min       ┆ 0.0       ┆ 0.0       ┆ 0.0       ┆ … ┆ 13475.0   ┆ 16650.0   ┆ 0.0      ┆ -1.0      │\n",
       "│ 25%       ┆ 2500.0    ┆ 0.0       ┆ 4.0       ┆ … ┆ 16544.0   ┆ 17256.0   ┆ 0.0      ┆ 0.0       │\n",
       "│ 50%       ┆ 5000.0    ┆ 1.0       ┆ 6.0       ┆ … ┆ 17409.0   ┆ 18021.0   ┆ 0.0      ┆ 0.0       │\n",
       "│ 75%       ┆ 7499.0    ┆ 1.0       ┆ 8.0       ┆ … ┆ 18274.0   ┆ 18472.0   ┆ 1.0      ┆ 0.0       │\n",
       "│ max       ┆ 9999.0    ┆ 1.0       ┆ 14.0      ┆ … ┆ 20619.0   ┆ 20101.0   ┆ 1.0      ┆ 2.0       │\n",
       "└───────────┴───────────┴───────────┴───────────┴───┴───────────┴───────────┴──────────┴───────────┘"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (3, 8)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>blueWins</th><th>blueFirstBlood_mean</th><th>blueKills_mean</th><th>blueDeaths_mean</th><th>blueDragons_mean</th><th>blueTotalGold_mean</th><th>blueTotalExperience_mean</th><th>blueHerald_mean</th></tr><tr><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0.401623</td><td>5.158633</td><td>6.541564</td><td>0.239302</td><td>17081.556567</td><td>17734.218396</td><td>0.130349</td></tr><tr><td>1</td><td>0.628114</td><td>6.930097</td><td>5.284698</td><td>0.480935</td><td>17229.011947</td><td>18241.174377</td><td>0.232334</td></tr><tr><td>null</td><td>0.5235</td><td>6.208</td><td>5.8825</td><td>0.3595</td><td>17178.094</td><td>18003.009</td><td>0.184</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (3, 8)\n",
       "┌──────────┬────────────┬────────────┬────────────┬────────────┬───────────┬───────────┬───────────┐\n",
       "│ blueWins ┆ blueFirstB ┆ blueKills_ ┆ blueDeaths ┆ blueDragon ┆ blueTotal ┆ blueTotal ┆ blueHeral │\n",
       "│ ---      ┆ lood_mean  ┆ mean       ┆ _mean      ┆ s_mean     ┆ Gold_mean ┆ Experienc ┆ d_mean    │\n",
       "│ i64      ┆ ---        ┆ ---        ┆ ---        ┆ ---        ┆ ---       ┆ e_mean    ┆ ---       │\n",
       "│          ┆ f64        ┆ f64        ┆ f64        ┆ f64        ┆ f64       ┆ ---       ┆ f64       │\n",
       "│          ┆            ┆            ┆            ┆            ┆           ┆ f64       ┆           │\n",
       "╞══════════╪════════════╪════════════╪════════════╪════════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0        ┆ 0.401623   ┆ 5.158633   ┆ 6.541564   ┆ 0.239302   ┆ 17081.556 ┆ 17734.218 ┆ 0.130349  │\n",
       "│          ┆            ┆            ┆            ┆            ┆ 567       ┆ 396       ┆           │\n",
       "│ 1        ┆ 0.628114   ┆ 6.930097   ┆ 5.284698   ┆ 0.480935   ┆ 17229.011 ┆ 18241.174 ┆ 0.232334  │\n",
       "│          ┆            ┆            ┆            ┆            ┆ 947       ┆ 377       ┆           │\n",
       "│ null     ┆ 0.5235     ┆ 6.208      ┆ 5.8825     ┆ 0.3595     ┆ 17178.094 ┆ 18003.009 ┆ 0.184     │\n",
       "└──────────┴────────────┴────────────┴────────────┴────────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df.group_by(pl.col(\"blueWins\")).agg(\n",
    "    pl.exclude(\"gameId\").mean().name.suffix(\"_mean\"),\n",
    "    # pl.exclude(\"gameId\").median().name.suffix(\"_median\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (10_000, 4_585)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gameId</th><th>blueFirstBlood</th><th>blueKills</th><th>blueDeaths</th><th>blueDragons</th><th>blueTotalGold</th><th>blueTotalExperience</th><th>blueWins</th><th>blueHerald</th><th>blueKills_max__blueFirstBlood_0</th><th>blueKills_min__blueFirstBlood_0</th><th>blueKills_mean__blueFirstBlood_0</th><th>blueKills_median__blueFirstBlood_0</th><th>blueKills_q25__blueFirstBlood_0</th><th>blueKills_q75__blueFirstBlood_0</th><th>blueKills_q33__blueFirstBlood_0</th><th>blueKills_q66__blueFirstBlood_0</th><th>blueKills_q20__blueFirstBlood_0</th><th>blueKills_q40__blueFirstBlood_0</th><th>blueKills_q60__blueFirstBlood_0</th><th>blueKills_q80__blueFirstBlood_0</th><th>blueKills_std__blueFirstBlood_0</th><th>blueKills_max__blueFirstBlood_1</th><th>blueKills_min__blueFirstBlood_1</th><th>blueKills_mean__blueFirstBlood_1</th><th>blueKills_median__blueFirstBlood_1</th><th>blueKills_q25__blueFirstBlood_1</th><th>blueKills_q75__blueFirstBlood_1</th><th>blueKills_q33__blueFirstBlood_1</th><th>blueKills_q66__blueFirstBlood_1</th><th>blueKills_q20__blueFirstBlood_1</th><th>blueKills_q40__blueFirstBlood_1</th><th>blueKills_q60__blueFirstBlood_1</th><th>blueKills_q80__blueFirstBlood_1</th><th>blueKills_std__blueFirstBlood_1</th><th>blueDeaths_max__blueFirstBlood_0</th><th>blueDeaths_min__blueFirstBlood_0</th><th>&hellip;</th><th>blueTotalExperience_mean__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_median__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q25__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q75__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q33__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q66__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q20__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q40__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q60__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_q80__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_std__blueFirstBloodblueHeraldblueDragons_combi_120</th><th>blueTotalExperience_max__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_min__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_mean__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_median__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q25__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q75__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q33__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q66__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q20__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q40__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q60__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_q80__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_std__blueFirstBloodblueHeraldblueDragons_combi_011</th><th>blueTotalExperience_max__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_min__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_mean__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_median__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q25__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q75__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q33__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q66__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q20__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q40__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q60__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_q80__blueFirstBloodblueHeraldblueDragons_combi_020</th><th>blueTotalExperience_std__blueFirstBloodblueHeraldblueDragons_combi_020</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td><td>i32</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>i32</td><td>i32</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>null</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>5</td><td>8</td><td>0</td><td>14536.0</td><td>17256.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>1</td><td>1</td><td>10</td><td>1</td><td>0</td><td>14536.0</td><td>17863.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>2</td><td>0</td><td>3</td><td>10</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>3</td><td>1</td><td>7</td><td>10</td><td>0</td><td>19558.0</td><td>18201.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>4</td><td>0</td><td>4</td><td>9</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>5</td><td>0</td><td>5</td><td>10</td><td>0</td><td>17409.0</td><td>19730.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>6</td><td>0</td><td>5</td><td>4</td><td>1</td><td>20038.0</td><td>19730.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>7</td><td>1</td><td>8</td><td>5</td><td>0</td><td>18274.0</td><td>18491.0</td><td>1</td><td>1</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>8</td><td>0</td><td>5</td><td>6</td><td>0</td><td>14536.0</td><td>18986.0</td><td>0</td><td>1</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>10</td><td>1</td><td>7</td><td>4</td><td>1</td><td>18274.0</td><td>18021.0</td><td>1</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>11</td><td>0</td><td>3</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>12</td><td>1</td><td>3</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9946</td><td>0</td><td>7</td><td>2</td><td>1</td><td>18274.0</td><td>18491.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9951</td><td>0</td><td>2</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9952</td><td>1</td><td>10</td><td>4</td><td>0</td><td>18513.0</td><td>18201.0</td><td>null</td><td>1</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9959</td><td>0</td><td>5</td><td>10</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9960</td><td>0</td><td>4</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9964</td><td>1</td><td>4</td><td>6</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9970</td><td>0</td><td>5</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9971</td><td>0</td><td>6</td><td>3</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9980</td><td>0</td><td>4</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9983</td><td>1</td><td>6</td><td>3</td><td>1</td><td>18513.0</td><td>18201.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9996</td><td>1</td><td>10</td><td>9</td><td>1</td><td>18513.0</td><td>18201.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr><tr><td>9999</td><td>0</td><td>7</td><td>11</td><td>0</td><td>18117.0</td><td>18201.0</td><td>null</td><td>0</td><td>12</td><td>0</td><td>5.26617</td><td>5.0</td><td>4.0</td><td>7.0</td><td>4.0</td><td>6.0</td><td>3.0</td><td>5.0</td><td>6.0</td><td>7.0</td><td>2.377741</td><td>14</td><td>0</td><td>6.75463</td><td>6.0</td><td>5.0</td><td>9.0</td><td>5.0</td><td>8.0</td><td>4.0</td><td>6.0</td><td>7.0</td><td>9.0</td><td>2.641183</td><td>14</td><td>0</td><td>&hellip;</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>18201.0</td><td>null</td><td>20004.0</td><td>16650.0</td><td>18517.675676</td><td>18472.0</td><td>18201.0</td><td>18491.0</td><td>18472.0</td><td>18491.0</td><td>18201.0</td><td>18472.0</td><td>18491.0</td><td>18491.0</td><td>646.182513</td><td>18201.0</td><td>17256.0</td><td>17728.5</td><td>17728.5</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>18201.0</td><td>668.215908</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (10_000, 4_585)\n",
       "┌────────┬────────────┬───────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ gameId ┆ blueFirstB ┆ blueKills ┆ blueDeaths ┆ … ┆ blueTotal ┆ blueTotal ┆ blueTotal ┆ blueTotal │\n",
       "│ ---    ┆ lood       ┆ ---       ┆ ---        ┆   ┆ Experienc ┆ Experienc ┆ Experienc ┆ Experienc │\n",
       "│ i64    ┆ ---        ┆ i64       ┆ i64        ┆   ┆ e_q40__bl ┆ e_q60__bl ┆ e_q80__bl ┆ e_std__bl │\n",
       "│        ┆ i64        ┆           ┆            ┆   ┆ ueFir…    ┆ ueFir…    ┆ ueFir…    ┆ ueFir…    │\n",
       "│        ┆            ┆           ┆            ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆           ┆            ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪════════════╪═══════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0      ┆ 0          ┆ 5         ┆ 8          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 1      ┆ 1          ┆ 10        ┆ 1          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 2      ┆ 0          ┆ 3         ┆ 10         ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 3      ┆ 1          ┆ 7         ┆ 10         ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 4      ┆ 0          ┆ 4         ┆ 9          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ …      ┆ …          ┆ …         ┆ …          ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 9971   ┆ 0          ┆ 6         ┆ 3          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 9980   ┆ 0          ┆ 4         ┆ 4          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 9983   ┆ 1          ┆ 6         ┆ 3          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 9996   ┆ 1          ┆ 10        ┆ 9          ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "│ 9999   ┆ 0          ┆ 7         ┆ 11         ┆ … ┆ 17256.0   ┆ 18201.0   ┆ 18201.0   ┆ 668.21590 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 8         │\n",
       "└────────┴────────────┴───────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical = [\"blueWins\", \"blueFirstBlood\", \"blueHerald\", \"blueDragons\"]\n",
    "numeric_cols = [\"blueKills\", \"blueDeaths\", \"blueTotalGold\", \"blueTotalExperience\"]\n",
    "\n",
    "tmp = train_df.with_columns(pl.col(categorical).cast(pl.String))\n",
    "\n",
    "tmp2 = all_df.clone()\n",
    "\n",
    "import xfeat\n",
    "\n",
    "r2 = xfeat.ConcatCombination(input_cols=categorical, r=2, drop_origin=2).fit_transform(\n",
    "    tmp.to_pandas()\n",
    ")\n",
    "r3 = xfeat.ConcatCombination(input_cols=categorical, r=3, drop_origin=2).fit_transform(\n",
    "    tmp.to_pandas()\n",
    ")\n",
    "\n",
    "tmp = pl.concat([tmp, pl.from_pandas(r2), pl.from_pandas(r3)], how=\"horizontal\")\n",
    "\n",
    "\n",
    "for cat_col in tmp.select(cs.string()).columns:\n",
    "    for num_col in numeric_cols:\n",
    "        a = tmp.group_by(pl.col(cat_col)).agg(\n",
    "            [\n",
    "                pl.col(num_col).max().alias(f\"{num_col}_max__{cat_col}\"),\n",
    "                pl.col(num_col).min().alias(f\"{num_col}_min__{cat_col}\"),\n",
    "                pl.col(num_col).mean().alias(f\"{num_col}_mean__{cat_col}\"),\n",
    "                pl.col(num_col).median().alias(f\"{num_col}_median__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.25).alias(f\"{num_col}_q25__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.75).alias(f\"{num_col}_q75__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.33).alias(f\"{num_col}_q33__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.66).alias(f\"{num_col}_q66__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.2).alias(f\"{num_col}_q20__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.4).alias(f\"{num_col}_q40__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.6).alias(f\"{num_col}_q60__{cat_col}\"),\n",
    "                pl.col(num_col).quantile(0.8).alias(f\"{num_col}_q80__{cat_col}\"),\n",
    "                pl.col(num_col).std().alias(f\"{num_col}_std__{cat_col}\"),\n",
    "            ]\n",
    "        )\n",
    "        for row in a.iter_rows():\n",
    "            cat = row[0]\n",
    "            for col, val in zip(a.columns[1:], row[1:]):\n",
    "                tmp2 = tmp2.with_columns(pl.lit(val).alias(f\"{col}_{cat}\"))\n",
    "tmp2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "wins_df = train_df.filter(pl.col(\"blueWins\") == 1)\n",
    "lose_df = train_df.filter(pl.col(\"blueWins\") == 1)\n",
    "\n",
    "win_kill_mean = wins_df[\"blueKills\"].mean()\n",
    "lose_kill_mean = lose_df[\"blueKills\"].mean()\n",
    "win_death_mean = wins_df[\"blueDeaths\"].mean()\n",
    "lose_death_mean = lose_df[\"blueDeaths\"].mean()\n",
    "win_experience_mean = wins_df[\"blueTotalExperience\"].mean()\n",
    "lose_experience_mean = lose_df[\"blueTotalExperience\"].mean()\n",
    "\n",
    "win_kill_median = wins_df[\"blueKills\"].median()\n",
    "lose_kill_median = lose_df[\"blueKills\"].median()\n",
    "win_death_median = wins_df[\"blueDeaths\"].median()\n",
    "lose_death_median = lose_df[\"blueDeaths\"].median()\n",
    "win_experience_median = wins_df[\"blueTotalExperience\"].median()\n",
    "lose_experience_median = lose_df[\"blueTotalExperience\"].median()\n",
    "\n",
    "win_kill_q25 = wins_df[\"blueKills\"].quantile(0.25)\n",
    "lose_kill_q25 = lose_df[\"blueKills\"].quantile(0.25)\n",
    "win_death_q25 = wins_df[\"blueDeaths\"].quantile(0.25)\n",
    "lose_death_q25 = lose_df[\"blueDeaths\"].quantile(0.25)\n",
    "win_experience_q25 = wins_df[\"blueTotalExperience\"].quantile(0.25)\n",
    "lose_experience_q25 = lose_df[\"blueTotalExperience\"].quantile(0.25)\n",
    "\n",
    "win_kill_q75 = wins_df[\"blueKills\"].quantile(0.75)\n",
    "lose_kill_q75 = lose_df[\"blueKills\"].quantile(0.75)\n",
    "win_death_q75 = wins_df[\"blueDeaths\"].quantile(0.75)\n",
    "lose_death_q75 = lose_df[\"blueDeaths\"].quantile(0.75)\n",
    "win_experience_q75 = wins_df[\"blueTotalExperience\"].quantile(0.75)\n",
    "lose_experience_q75 = lose_df[\"blueTotalExperience\"].quantile(0.75)\n",
    "\n",
    "win_kill_q33 = wins_df[\"blueKills\"].quantile(0.33)\n",
    "lose_kill_q33 = lose_df[\"blueKills\"].quantile(0.33)\n",
    "win_death_q33 = wins_df[\"blueDeaths\"].quantile(0.33)\n",
    "lose_death_q33 = lose_df[\"blueDeaths\"].quantile(0.33)\n",
    "win_experience_q33 = wins_df[\"blueTotalExperience\"].quantile(0.33)\n",
    "lose_experience_q33 = lose_df[\"blueTotalExperience\"].quantile(0.33)\n",
    "\n",
    "win_kill_q66 = wins_df[\"blueKills\"].quantile(0.66)\n",
    "lose_kill_q66 = lose_df[\"blueKills\"].quantile(0.66)\n",
    "win_death_q66 = wins_df[\"blueDeaths\"].quantile(0.66)\n",
    "lose_death_q66 = lose_df[\"blueDeaths\"].quantile(0.66)\n",
    "win_experience_q66 = wins_df[\"blueTotalExperience\"].quantile(0.66)\n",
    "lose_experience_q66 = lose_df[\"blueTotalExperience\"].quantile(0.66)\n",
    "\n",
    "win_kill_q20 = wins_df[\"blueKills\"].quantile(0.20)\n",
    "lose_kill_q20 = lose_df[\"blueKills\"].quantile(0.20)\n",
    "win_death_q20 = wins_df[\"blueDeaths\"].quantile(0.20)\n",
    "lose_death_q20 = lose_df[\"blueDeaths\"].quantile(0.20)\n",
    "win_experience_q20 = wins_df[\"blueTotalExperience\"].quantile(0.20)\n",
    "lose_experience_q20 = lose_df[\"blueTotalExperience\"].quantile(0.20)\n",
    "\n",
    "win_kill_q40 = wins_df[\"blueKills\"].quantile(0.40)\n",
    "lose_kill_q40 = lose_df[\"blueKills\"].quantile(0.40)\n",
    "win_death_q40 = wins_df[\"blueDeaths\"].quantile(0.40)\n",
    "lose_death_q40 = lose_df[\"blueDeaths\"].quantile(0.40)\n",
    "win_experience_q40 = wins_df[\"blueTotalExperience\"].quantile(0.40)\n",
    "lose_experience_q40 = lose_df[\"blueTotalExperience\"].quantile(0.40)\n",
    "\n",
    "win_kill_q60 = wins_df[\"blueKills\"].quantile(0.60)\n",
    "lose_kill_q60 = lose_df[\"blueKills\"].quantile(0.60)\n",
    "win_death_q60 = wins_df[\"blueDeaths\"].quantile(0.60)\n",
    "lose_death_q60 = lose_df[\"blueDeaths\"].quantile(0.60)\n",
    "win_experience_q60 = wins_df[\"blueTotalExperience\"].quantile(0.60)\n",
    "lose_experience_q60 = lose_df[\"blueTotalExperience\"].quantile(0.60)\n",
    "\n",
    "win_kill_q80 = wins_df[\"blueKills\"].quantile(0.80)\n",
    "lose_kill_q80 = lose_df[\"blueKills\"].quantile(0.80)\n",
    "win_death_q80 = wins_df[\"blueDeaths\"].quantile(0.80)\n",
    "lose_death_q80 = lose_df[\"blueDeaths\"].quantile(0.80)\n",
    "win_experience_q80 = wins_df[\"blueTotalExperience\"].quantile(0.80)\n",
    "lose_experience_q80 = lose_df[\"blueTotalExperience\"].quantile(0.80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "statics_df = all_df.select(\n",
    "    (pl.col(\"blueKills\") - win_kill_mean).name.suffix(\"_win_mean_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_mean).name.suffix(\"_lose_mean_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_mean).name.suffix(\"_win_mean_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_mean).name.suffix(\"_lose_mean_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_mean).name.suffix(\"_win_mean_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_mean).name.suffix(\n",
    "        \"_lose_mean_diff\"\n",
    "    ),\n",
    "    (pl.col(\"blueKills\") - win_kill_median).name.suffix(\"_win_median_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_median).name.suffix(\"_lose_median_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_median).name.suffix(\"_win_median_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_median).name.suffix(\"_lose_median_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_median).name.suffix(\n",
    "        \"_win_median_diff\"\n",
    "    ),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_median).name.suffix(\n",
    "        \"_lose_median_diff\"\n",
    "    ),\n",
    "    (pl.col(\"blueKills\") - win_kill_q25).name.suffix(\"_win_q25_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q25).name.suffix(\"_lose_q25_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q25).name.suffix(\"_win_q25_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q25).name.suffix(\"_lose_q25_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q25).name.suffix(\"_win_q25_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q25).name.suffix(\"_lose_q25_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q75).name.suffix(\"_win_q75_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q75).name.suffix(\"_lose_q75_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q75).name.suffix(\"_win_q75_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q75).name.suffix(\"_lose_q75_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q75).name.suffix(\"_win_q75_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q75).name.suffix(\"_lose_q75_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q33).name.suffix(\"_win_q33_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q33).name.suffix(\"_lose_q33_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q33).name.suffix(\"_win_q33_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q33).name.suffix(\"_lose_q33_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q33).name.suffix(\"_win_q33_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q33).name.suffix(\"_lose_q33_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q66).name.suffix(\"_win_q66_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q66).name.suffix(\"_lose_q66_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q66).name.suffix(\"_win_q66_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q66).name.suffix(\"_lose_q66_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q66).name.suffix(\"_win_q66_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q66).name.suffix(\"_lose_q66_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q20).name.suffix(\"_win_q20_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q20).name.suffix(\"_lose_q20_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q20).name.suffix(\"_win_q20_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q20).name.suffix(\"_lose_q20_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q20).name.suffix(\"_win_q20_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q20).name.suffix(\"_lose_q20_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q40).name.suffix(\"_win_q40_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q40).name.suffix(\"_lose_q40_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q40).name.suffix(\"_win_q40_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q40).name.suffix(\"_lose_q40_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q40).name.suffix(\"_win_q40_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q40).name.suffix(\"_lose_q40_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q60).name.suffix(\"_win_q60_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q60).name.suffix(\"_lose_q60_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q60).name.suffix(\"_win_q60_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q60).name.suffix(\"_lose_q60_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q60).name.suffix(\"_win_q60_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q60).name.suffix(\"_lose_q60_diff\"),\n",
    "    (pl.col(\"blueKills\") - win_kill_q80).name.suffix(\"_win_q80_diff\"),\n",
    "    (pl.col(\"blueKills\") - lose_kill_q80).name.suffix(\"_lose_q80_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - win_death_q80).name.suffix(\"_win_q80_diff\"),\n",
    "    (pl.col(\"blueDeaths\") - lose_death_q80).name.suffix(\"_lose_q80_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - win_experience_q80).name.suffix(\"_win_q80_diff\"),\n",
    "    (pl.col(\"blueTotalExperience\") - lose_experience_q80).name.suffix(\"_lose_q80_diff\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = [\"blueFirstBlood\", \"blueHerald\", \"blueDragons\"]\n",
    "numeric_cols = [\"blueKills\", \"blueDeaths\", \"blueTotalGold\", \"blueTotalExperience\"]\n",
    "\n",
    "exprs = [\n",
    "    [\n",
    "        pl.col(num).mean().over(cat).name.suffix(f\"_{cat}_mean\"),\n",
    "        pl.col(num).max().over(cat).name.suffix(f\"_{cat}_max\"),\n",
    "        pl.col(num).min().over(cat).name.suffix(f\"_{cat}_min\"),\n",
    "        pl.col(num).median().over(cat).name.suffix(f\"_{cat}_median\"),\n",
    "        pl.col(num).quantile(0.25).over(cat).name.suffix(f\"_{cat}_q25\"),\n",
    "        pl.col(num).quantile(0.75).over(cat).name.suffix(f\"_{cat}_q75\"),\n",
    "        pl.col(num).std().over(cat).name.suffix(f\"_{cat}_std\"),\n",
    "    ]\n",
    "    for num in numeric_cols\n",
    "    for cat in categorical\n",
    "]\n",
    "\n",
    "\n",
    "agg_df = all_df.select(sum(exprs, []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = pl.col(\"blueWins\")\n",
    "\n",
    "features_df = pl.concat([all_df, statics_df, agg_df], how=\"horizontal\")\n",
    "\n",
    "train_df = features_df.filter(target_col.is_not_null())\n",
    "test_df = features_df.filter(target_col.is_null())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (8_000, 153)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gameId</th><th>blueFirstBlood</th><th>blueKills</th><th>blueDeaths</th><th>blueDragons</th><th>blueTotalGold</th><th>blueTotalExperience</th><th>blueWins</th><th>blueHerald</th><th>blueKills_win_mean_diff</th><th>blueKills_lose_mean_diff</th><th>blueDeaths_win_mean_diff</th><th>blueDeaths_lose_mean_diff</th><th>blueTotalExperience_win_mean_diff</th><th>blueTotalExperience_lose_mean_diff</th><th>blueKills_win_median_diff</th><th>blueKills_lose_median_diff</th><th>blueDeaths_win_median_diff</th><th>blueDeaths_lose_median_diff</th><th>blueTotalExperience_win_median_diff</th><th>blueTotalExperience_lose_median_diff</th><th>blueKills_win_q25_diff</th><th>blueKills_lose_q25_diff</th><th>blueDeaths_win_q25_diff</th><th>blueDeaths_lose_q25_diff</th><th>blueTotalExperience_win_q25_diff</th><th>blueTotalExperience_lose_q25_diff</th><th>blueKills_win_q75_diff</th><th>blueKills_lose_q75_diff</th><th>blueDeaths_win_q75_diff</th><th>blueDeaths_lose_q75_diff</th><th>blueTotalExperience_win_q75_diff</th><th>blueTotalExperience_lose_q75_diff</th><th>blueKills_win_q33_diff</th><th>blueKills_lose_q33_diff</th><th>blueDeaths_win_q33_diff</th><th>blueDeaths_lose_q33_diff</th><th>&hellip;</th><th>blueTotalGold_blueFirstBlood_q75</th><th>blueTotalGold_blueFirstBlood_std</th><th>blueTotalGold_blueHerald_mean</th><th>blueTotalGold_blueHerald_max</th><th>blueTotalGold_blueHerald_min</th><th>blueTotalGold_blueHerald_median</th><th>blueTotalGold_blueHerald_q25</th><th>blueTotalGold_blueHerald_q75</th><th>blueTotalGold_blueHerald_std</th><th>blueTotalGold_blueDragons_mean</th><th>blueTotalGold_blueDragons_max</th><th>blueTotalGold_blueDragons_min</th><th>blueTotalGold_blueDragons_median</th><th>blueTotalGold_blueDragons_q25</th><th>blueTotalGold_blueDragons_q75</th><th>blueTotalGold_blueDragons_std</th><th>blueTotalExperience_blueFirstBlood_mean</th><th>blueTotalExperience_blueFirstBlood_max</th><th>blueTotalExperience_blueFirstBlood_min</th><th>blueTotalExperience_blueFirstBlood_median</th><th>blueTotalExperience_blueFirstBlood_q25</th><th>blueTotalExperience_blueFirstBlood_q75</th><th>blueTotalExperience_blueFirstBlood_std</th><th>blueTotalExperience_blueHerald_mean</th><th>blueTotalExperience_blueHerald_max</th><th>blueTotalExperience_blueHerald_min</th><th>blueTotalExperience_blueHerald_median</th><th>blueTotalExperience_blueHerald_q25</th><th>blueTotalExperience_blueHerald_q75</th><th>blueTotalExperience_blueHerald_std</th><th>blueTotalExperience_blueDragons_mean</th><th>blueTotalExperience_blueDragons_max</th><th>blueTotalExperience_blueDragons_min</th><th>blueTotalExperience_blueDragons_median</th><th>blueTotalExperience_blueDragons_q25</th><th>blueTotalExperience_blueDragons_q75</th><th>blueTotalExperience_blueDragons_std</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>0</td><td>0</td><td>5</td><td>8</td><td>0</td><td>14536.0</td><td>17256.0</td><td>0</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-2.0</td><td>-2.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-4.0</td><td>-4.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-1.0</td><td>-1.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>1</td><td>1</td><td>10</td><td>1</td><td>0</td><td>14536.0</td><td>17863.0</td><td>0</td><td>0</td><td>3.069903</td><td>3.069903</td><td>-4.284698</td><td>-4.284698</td><td>-378.174377</td><td>-378.174377</td><td>3.0</td><td>3.0</td><td>-4.0</td><td>-4.0</td><td>-338.0</td><td>-338.0</td><td>5.0</td><td>5.0</td><td>-3.0</td><td>-3.0</td><td>-158.0</td><td>-158.0</td><td>1.0</td><td>1.0</td><td>-6.0</td><td>-6.0</td><td>-628.0</td><td>-628.0</td><td>4.0</td><td>4.0</td><td>-3.0</td><td>-3.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>2</td><td>0</td><td>3</td><td>10</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>4.715302</td><td>4.715302</td><td>-985.174377</td><td>-985.174377</td><td>-4.0</td><td>-4.0</td><td>5.0</td><td>5.0</td><td>-945.0</td><td>-945.0</td><td>-2.0</td><td>-2.0</td><td>6.0</td><td>6.0</td><td>-765.0</td><td>-765.0</td><td>-6.0</td><td>-6.0</td><td>3.0</td><td>3.0</td><td>-1235.0</td><td>-1235.0</td><td>-3.0</td><td>-3.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>3</td><td>1</td><td>7</td><td>10</td><td>0</td><td>19558.0</td><td>18201.0</td><td>0</td><td>0</td><td>0.069903</td><td>0.069903</td><td>4.715302</td><td>4.715302</td><td>-40.174377</td><td>-40.174377</td><td>0.0</td><td>0.0</td><td>5.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>6.0</td><td>6.0</td><td>180.0</td><td>180.0</td><td>-2.0</td><td>-2.0</td><td>3.0</td><td>3.0</td><td>-290.0</td><td>-290.0</td><td>1.0</td><td>1.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>4</td><td>0</td><td>4</td><td>9</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-2.930097</td><td>-2.930097</td><td>3.715302</td><td>3.715302</td><td>-985.174377</td><td>-985.174377</td><td>-3.0</td><td>-3.0</td><td>4.0</td><td>4.0</td><td>-945.0</td><td>-945.0</td><td>-1.0</td><td>-1.0</td><td>5.0</td><td>5.0</td><td>-765.0</td><td>-765.0</td><td>-5.0</td><td>-5.0</td><td>2.0</td><td>2.0</td><td>-1235.0</td><td>-1235.0</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>5</td><td>0</td><td>5</td><td>10</td><td>0</td><td>17409.0</td><td>19730.0</td><td>0</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>4.715302</td><td>4.715302</td><td>1488.825623</td><td>1488.825623</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>1529.0</td><td>1529.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>1709.0</td><td>1709.0</td><td>-4.0</td><td>-4.0</td><td>3.0</td><td>3.0</td><td>1239.0</td><td>1239.0</td><td>-1.0</td><td>-1.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>6</td><td>0</td><td>5</td><td>4</td><td>1</td><td>20038.0</td><td>19730.0</td><td>0</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>-1.284698</td><td>-1.284698</td><td>1488.825623</td><td>1488.825623</td><td>-2.0</td><td>-2.0</td><td>-1.0</td><td>-1.0</td><td>1529.0</td><td>1529.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>1709.0</td><td>1709.0</td><td>-4.0</td><td>-4.0</td><td>-3.0</td><td>-3.0</td><td>1239.0</td><td>1239.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>7</td><td>1</td><td>8</td><td>5</td><td>0</td><td>18274.0</td><td>18491.0</td><td>1</td><td>1</td><td>1.069903</td><td>1.069903</td><td>-0.284698</td><td>-0.284698</td><td>249.825623</td><td>249.825623</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>290.0</td><td>290.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>1.0</td><td>470.0</td><td>470.0</td><td>-1.0</td><td>-1.0</td><td>-2.0</td><td>-2.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>8</td><td>0</td><td>5</td><td>6</td><td>0</td><td>14536.0</td><td>18986.0</td><td>0</td><td>1</td><td>-1.930097</td><td>-1.930097</td><td>0.715302</td><td>0.715302</td><td>744.825623</td><td>744.825623</td><td>-2.0</td><td>-2.0</td><td>1.0</td><td>1.0</td><td>785.0</td><td>785.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>965.0</td><td>965.0</td><td>-4.0</td><td>-4.0</td><td>-1.0</td><td>-1.0</td><td>495.0</td><td>495.0</td><td>-1.0</td><td>-1.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>10</td><td>1</td><td>7</td><td>4</td><td>1</td><td>18274.0</td><td>18021.0</td><td>1</td><td>0</td><td>0.069903</td><td>0.069903</td><td>-1.284698</td><td>-1.284698</td><td>-220.174377</td><td>-220.174377</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>-180.0</td><td>-180.0</td><td>2.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-2.0</td><td>-2.0</td><td>-3.0</td><td>-3.0</td><td>-470.0</td><td>-470.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>11</td><td>0</td><td>3</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-4.0</td><td>-4.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>-2.0</td><td>-2.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-6.0</td><td>-6.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-3.0</td><td>-3.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>12</td><td>1</td><td>3</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-4.0</td><td>-4.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>-2.0</td><td>-2.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-6.0</td><td>-6.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-3.0</td><td>-3.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9986</td><td>1</td><td>8</td><td>1</td><td>1</td><td>18274.0</td><td>18491.0</td><td>1</td><td>0</td><td>1.069903</td><td>1.069903</td><td>-4.284698</td><td>-4.284698</td><td>249.825623</td><td>249.825623</td><td>1.0</td><td>1.0</td><td>-4.0</td><td>-4.0</td><td>290.0</td><td>290.0</td><td>3.0</td><td>3.0</td><td>-3.0</td><td>-3.0</td><td>470.0</td><td>470.0</td><td>-1.0</td><td>-1.0</td><td>-6.0</td><td>-6.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>-3.0</td><td>-3.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9987</td><td>1</td><td>8</td><td>8</td><td>1</td><td>18274.0</td><td>18491.0</td><td>1</td><td>0</td><td>1.069903</td><td>1.069903</td><td>2.715302</td><td>2.715302</td><td>249.825623</td><td>249.825623</td><td>1.0</td><td>1.0</td><td>3.0</td><td>3.0</td><td>290.0</td><td>290.0</td><td>3.0</td><td>3.0</td><td>4.0</td><td>4.0</td><td>470.0</td><td>470.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9988</td><td>1</td><td>4</td><td>5</td><td>1</td><td>16544.0</td><td>18201.0</td><td>0</td><td>1</td><td>-2.930097</td><td>-2.930097</td><td>-0.284698</td><td>-0.284698</td><td>-40.174377</td><td>-40.174377</td><td>-3.0</td><td>-3.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>180.0</td><td>180.0</td><td>-5.0</td><td>-5.0</td><td>-2.0</td><td>-2.0</td><td>-290.0</td><td>-290.0</td><td>-2.0</td><td>-2.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9989</td><td>0</td><td>4</td><td>10</td><td>1</td><td>18117.0</td><td>20004.0</td><td>1</td><td>0</td><td>-2.930097</td><td>-2.930097</td><td>4.715302</td><td>4.715302</td><td>1762.825623</td><td>1762.825623</td><td>-3.0</td><td>-3.0</td><td>5.0</td><td>5.0</td><td>1803.0</td><td>1803.0</td><td>-1.0</td><td>-1.0</td><td>6.0</td><td>6.0</td><td>1983.0</td><td>1983.0</td><td>-5.0</td><td>-5.0</td><td>3.0</td><td>3.0</td><td>1513.0</td><td>1513.0</td><td>-2.0</td><td>-2.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9990</td><td>1</td><td>3</td><td>9</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>3.715302</td><td>3.715302</td><td>-985.174377</td><td>-985.174377</td><td>-4.0</td><td>-4.0</td><td>4.0</td><td>4.0</td><td>-945.0</td><td>-945.0</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>-765.0</td><td>-765.0</td><td>-6.0</td><td>-6.0</td><td>2.0</td><td>2.0</td><td>-1235.0</td><td>-1235.0</td><td>-3.0</td><td>-3.0</td><td>5.0</td><td>5.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9991</td><td>0</td><td>5</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-2.0</td><td>-2.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-4.0</td><td>-4.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-1.0</td><td>-1.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9992</td><td>1</td><td>10</td><td>4</td><td>1</td><td>18274.0</td><td>18491.0</td><td>1</td><td>0</td><td>3.069903</td><td>3.069903</td><td>-1.284698</td><td>-1.284698</td><td>249.825623</td><td>249.825623</td><td>3.0</td><td>3.0</td><td>-1.0</td><td>-1.0</td><td>290.0</td><td>290.0</td><td>5.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>470.0</td><td>470.0</td><td>1.0</td><td>1.0</td><td>-3.0</td><td>-3.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9993</td><td>1</td><td>9</td><td>6</td><td>0</td><td>18513.0</td><td>18201.0</td><td>1</td><td>0</td><td>2.069903</td><td>2.069903</td><td>0.715302</td><td>0.715302</td><td>-40.174377</td><td>-40.174377</td><td>2.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>2.0</td><td>2.0</td><td>180.0</td><td>180.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>-290.0</td><td>-290.0</td><td>3.0</td><td>3.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9994</td><td>0</td><td>3</td><td>10</td><td>0</td><td>17381.0</td><td>19797.0</td><td>0</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>4.715302</td><td>4.715302</td><td>1555.825623</td><td>1555.825623</td><td>-4.0</td><td>-4.0</td><td>5.0</td><td>5.0</td><td>1596.0</td><td>1596.0</td><td>-2.0</td><td>-2.0</td><td>6.0</td><td>6.0</td><td>1776.0</td><td>1776.0</td><td>-6.0</td><td>-6.0</td><td>3.0</td><td>3.0</td><td>1306.0</td><td>1306.0</td><td>-3.0</td><td>-3.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9995</td><td>1</td><td>9</td><td>3</td><td>1</td><td>18274.0</td><td>18491.0</td><td>1</td><td>1</td><td>2.069903</td><td>2.069903</td><td>-2.284698</td><td>-2.284698</td><td>249.825623</td><td>249.825623</td><td>2.0</td><td>2.0</td><td>-2.0</td><td>-2.0</td><td>290.0</td><td>290.0</td><td>4.0</td><td>4.0</td><td>-1.0</td><td>-1.0</td><td>470.0</td><td>470.0</td><td>0.0</td><td>0.0</td><td>-4.0</td><td>-4.0</td><td>0.0</td><td>0.0</td><td>3.0</td><td>3.0</td><td>-1.0</td><td>-1.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9997</td><td>0</td><td>5</td><td>10</td><td>1</td><td>18274.0</td><td>18491.0</td><td>1</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>4.715302</td><td>4.715302</td><td>249.825623</td><td>249.825623</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>290.0</td><td>290.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>470.0</td><td>470.0</td><td>-4.0</td><td>-4.0</td><td>3.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9998</td><td>0</td><td>6</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>0</td><td>0</td><td>-0.930097</td><td>-0.930097</td><td>-1.284698</td><td>-1.284698</td><td>-985.174377</td><td>-985.174377</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-945.0</td><td>-945.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>-765.0</td><td>-765.0</td><td>-3.0</td><td>-3.0</td><td>-3.0</td><td>-3.0</td><td>-1235.0</td><td>-1235.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (8_000, 153)\n",
       "┌────────┬────────────┬───────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ gameId ┆ blueFirstB ┆ blueKills ┆ blueDeaths ┆ … ┆ blueTotal ┆ blueTotal ┆ blueTotal ┆ blueTotal │\n",
       "│ ---    ┆ lood       ┆ ---       ┆ ---        ┆   ┆ Experienc ┆ Experienc ┆ Experienc ┆ Experienc │\n",
       "│ i64    ┆ ---        ┆ i64       ┆ i64        ┆   ┆ e_blueDra ┆ e_blueDra ┆ e_blueDra ┆ e_blueDra │\n",
       "│        ┆ i64        ┆           ┆            ┆   ┆ gons_…    ┆ gons_…    ┆ gons_…    ┆ gons_…    │\n",
       "│        ┆            ┆           ┆            ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆           ┆            ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪════════════╪═══════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 0      ┆ 0          ┆ 5         ┆ 8          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 1      ┆ 1          ┆ 10        ┆ 1          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 2      ┆ 0          ┆ 3         ┆ 10         ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 3      ┆ 1          ┆ 7         ┆ 10         ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 4      ┆ 0          ┆ 4         ┆ 9          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ …      ┆ …          ┆ …         ┆ …          ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 9993   ┆ 1          ┆ 9         ┆ 6          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 9994   ┆ 0          ┆ 3         ┆ 10         ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 9995   ┆ 1          ┆ 9         ┆ 3          ┆ … ┆ 18201.0   ┆ 18021.0   ┆ 18491.0   ┆ 596.92925 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 9997   ┆ 0          ┆ 5         ┆ 10         ┆ … ┆ 18201.0   ┆ 18021.0   ┆ 18491.0   ┆ 596.92925 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 9998   ┆ 0          ┆ 6         ┆ 4          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "└────────┴────────────┴───────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div><style>\n",
       ".dataframe > thead > tr,\n",
       ".dataframe > tbody > tr {\n",
       "  text-align: right;\n",
       "  white-space: pre-wrap;\n",
       "}\n",
       "</style>\n",
       "<small>shape: (2_000, 153)</small><table border=\"1\" class=\"dataframe\"><thead><tr><th>gameId</th><th>blueFirstBlood</th><th>blueKills</th><th>blueDeaths</th><th>blueDragons</th><th>blueTotalGold</th><th>blueTotalExperience</th><th>blueWins</th><th>blueHerald</th><th>blueKills_win_mean_diff</th><th>blueKills_lose_mean_diff</th><th>blueDeaths_win_mean_diff</th><th>blueDeaths_lose_mean_diff</th><th>blueTotalExperience_win_mean_diff</th><th>blueTotalExperience_lose_mean_diff</th><th>blueKills_win_median_diff</th><th>blueKills_lose_median_diff</th><th>blueDeaths_win_median_diff</th><th>blueDeaths_lose_median_diff</th><th>blueTotalExperience_win_median_diff</th><th>blueTotalExperience_lose_median_diff</th><th>blueKills_win_q25_diff</th><th>blueKills_lose_q25_diff</th><th>blueDeaths_win_q25_diff</th><th>blueDeaths_lose_q25_diff</th><th>blueTotalExperience_win_q25_diff</th><th>blueTotalExperience_lose_q25_diff</th><th>blueKills_win_q75_diff</th><th>blueKills_lose_q75_diff</th><th>blueDeaths_win_q75_diff</th><th>blueDeaths_lose_q75_diff</th><th>blueTotalExperience_win_q75_diff</th><th>blueTotalExperience_lose_q75_diff</th><th>blueKills_win_q33_diff</th><th>blueKills_lose_q33_diff</th><th>blueDeaths_win_q33_diff</th><th>blueDeaths_lose_q33_diff</th><th>&hellip;</th><th>blueTotalGold_blueFirstBlood_q75</th><th>blueTotalGold_blueFirstBlood_std</th><th>blueTotalGold_blueHerald_mean</th><th>blueTotalGold_blueHerald_max</th><th>blueTotalGold_blueHerald_min</th><th>blueTotalGold_blueHerald_median</th><th>blueTotalGold_blueHerald_q25</th><th>blueTotalGold_blueHerald_q75</th><th>blueTotalGold_blueHerald_std</th><th>blueTotalGold_blueDragons_mean</th><th>blueTotalGold_blueDragons_max</th><th>blueTotalGold_blueDragons_min</th><th>blueTotalGold_blueDragons_median</th><th>blueTotalGold_blueDragons_q25</th><th>blueTotalGold_blueDragons_q75</th><th>blueTotalGold_blueDragons_std</th><th>blueTotalExperience_blueFirstBlood_mean</th><th>blueTotalExperience_blueFirstBlood_max</th><th>blueTotalExperience_blueFirstBlood_min</th><th>blueTotalExperience_blueFirstBlood_median</th><th>blueTotalExperience_blueFirstBlood_q25</th><th>blueTotalExperience_blueFirstBlood_q75</th><th>blueTotalExperience_blueFirstBlood_std</th><th>blueTotalExperience_blueHerald_mean</th><th>blueTotalExperience_blueHerald_max</th><th>blueTotalExperience_blueHerald_min</th><th>blueTotalExperience_blueHerald_median</th><th>blueTotalExperience_blueHerald_q25</th><th>blueTotalExperience_blueHerald_q75</th><th>blueTotalExperience_blueHerald_std</th><th>blueTotalExperience_blueDragons_mean</th><th>blueTotalExperience_blueDragons_max</th><th>blueTotalExperience_blueDragons_min</th><th>blueTotalExperience_blueDragons_median</th><th>blueTotalExperience_blueDragons_q25</th><th>blueTotalExperience_blueDragons_q75</th><th>blueTotalExperience_blueDragons_std</th></tr><tr><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>i64</td><td>i64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>&hellip;</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td><td>f64</td></tr></thead><tbody><tr><td>9</td><td>0</td><td>7</td><td>6</td><td>0</td><td>16961.0</td><td>18201.0</td><td>null</td><td>0</td><td>0.069903</td><td>0.069903</td><td>0.715302</td><td>0.715302</td><td>-40.174377</td><td>-40.174377</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>2.0</td><td>180.0</td><td>180.0</td><td>-2.0</td><td>-2.0</td><td>-1.0</td><td>-1.0</td><td>-290.0</td><td>-290.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>15</td><td>0</td><td>6</td><td>6</td><td>1</td><td>18513.0</td><td>18021.0</td><td>null</td><td>1</td><td>-0.930097</td><td>-0.930097</td><td>0.715302</td><td>0.715302</td><td>-220.174377</td><td>-220.174377</td><td>-1.0</td><td>-1.0</td><td>1.0</td><td>1.0</td><td>-180.0</td><td>-180.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>0.0</td><td>0.0</td><td>-3.0</td><td>-3.0</td><td>-1.0</td><td>-1.0</td><td>-470.0</td><td>-470.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>18</td><td>1</td><td>6</td><td>4</td><td>0</td><td>13475.0</td><td>17256.0</td><td>null</td><td>0</td><td>-0.930097</td><td>-0.930097</td><td>-1.284698</td><td>-1.284698</td><td>-985.174377</td><td>-985.174377</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-1.0</td><td>-945.0</td><td>-945.0</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>-765.0</td><td>-765.0</td><td>-3.0</td><td>-3.0</td><td>-3.0</td><td>-3.0</td><td>-1235.0</td><td>-1235.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>23</td><td>0</td><td>5</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>-1.284698</td><td>-1.284698</td><td>-985.174377</td><td>-985.174377</td><td>-2.0</td><td>-2.0</td><td>-1.0</td><td>-1.0</td><td>-945.0</td><td>-945.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>0.0</td><td>-765.0</td><td>-765.0</td><td>-4.0</td><td>-4.0</td><td>-3.0</td><td>-3.0</td><td>-1235.0</td><td>-1235.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>31</td><td>0</td><td>10</td><td>8</td><td>0</td><td>18117.0</td><td>18472.0</td><td>null</td><td>0</td><td>3.069903</td><td>3.069903</td><td>2.715302</td><td>2.715302</td><td>230.825623</td><td>230.825623</td><td>3.0</td><td>3.0</td><td>3.0</td><td>3.0</td><td>271.0</td><td>271.0</td><td>5.0</td><td>5.0</td><td>4.0</td><td>4.0</td><td>451.0</td><td>451.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>1.0</td><td>-19.0</td><td>-19.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>32</td><td>0</td><td>7</td><td>8</td><td>0</td><td>19558.0</td><td>18201.0</td><td>null</td><td>1</td><td>0.069903</td><td>0.069903</td><td>2.715302</td><td>2.715302</td><td>-40.174377</td><td>-40.174377</td><td>0.0</td><td>0.0</td><td>3.0</td><td>3.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>4.0</td><td>4.0</td><td>180.0</td><td>180.0</td><td>-2.0</td><td>-2.0</td><td>1.0</td><td>1.0</td><td>-290.0</td><td>-290.0</td><td>1.0</td><td>1.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>33</td><td>0</td><td>6</td><td>10</td><td>0</td><td>14536.0</td><td>17256.0</td><td>null</td><td>0</td><td>-0.930097</td><td>-0.930097</td><td>4.715302</td><td>4.715302</td><td>-985.174377</td><td>-985.174377</td><td>-1.0</td><td>-1.0</td><td>5.0</td><td>5.0</td><td>-945.0</td><td>-945.0</td><td>1.0</td><td>1.0</td><td>6.0</td><td>6.0</td><td>-765.0</td><td>-765.0</td><td>-3.0</td><td>-3.0</td><td>3.0</td><td>3.0</td><td>-1235.0</td><td>-1235.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>36</td><td>1</td><td>6</td><td>2</td><td>0</td><td>18274.0</td><td>18021.0</td><td>null</td><td>1</td><td>-0.930097</td><td>-0.930097</td><td>-3.284698</td><td>-3.284698</td><td>-220.174377</td><td>-220.174377</td><td>-1.0</td><td>-1.0</td><td>-3.0</td><td>-3.0</td><td>-180.0</td><td>-180.0</td><td>1.0</td><td>1.0</td><td>-2.0</td><td>-2.0</td><td>0.0</td><td>0.0</td><td>-3.0</td><td>-3.0</td><td>-5.0</td><td>-5.0</td><td>-470.0</td><td>-470.0</td><td>0.0</td><td>0.0</td><td>-2.0</td><td>-2.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>38</td><td>0</td><td>8</td><td>5</td><td>1</td><td>18274.0</td><td>18472.0</td><td>null</td><td>0</td><td>1.069903</td><td>1.069903</td><td>-0.284698</td><td>-0.284698</td><td>230.825623</td><td>230.825623</td><td>1.0</td><td>1.0</td><td>0.0</td><td>0.0</td><td>271.0</td><td>271.0</td><td>3.0</td><td>3.0</td><td>1.0</td><td>1.0</td><td>451.0</td><td>451.0</td><td>-1.0</td><td>-1.0</td><td>-2.0</td><td>-2.0</td><td>-19.0</td><td>-19.0</td><td>2.0</td><td>2.0</td><td>1.0</td><td>1.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>39</td><td>1</td><td>4</td><td>9</td><td>1</td><td>19558.0</td><td>18201.0</td><td>null</td><td>1</td><td>-2.930097</td><td>-2.930097</td><td>3.715302</td><td>3.715302</td><td>-40.174377</td><td>-40.174377</td><td>-3.0</td><td>-3.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>5.0</td><td>5.0</td><td>180.0</td><td>180.0</td><td>-5.0</td><td>-5.0</td><td>2.0</td><td>2.0</td><td>-290.0</td><td>-290.0</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>42</td><td>1</td><td>3</td><td>6</td><td>1</td><td>13475.0</td><td>17256.0</td><td>null</td><td>0</td><td>-3.930097</td><td>-3.930097</td><td>0.715302</td><td>0.715302</td><td>-985.174377</td><td>-985.174377</td><td>-4.0</td><td>-4.0</td><td>1.0</td><td>1.0</td><td>-945.0</td><td>-945.0</td><td>-2.0</td><td>-2.0</td><td>2.0</td><td>2.0</td><td>-765.0</td><td>-765.0</td><td>-6.0</td><td>-6.0</td><td>-1.0</td><td>-1.0</td><td>-1235.0</td><td>-1235.0</td><td>-3.0</td><td>-3.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>44</td><td>0</td><td>7</td><td>11</td><td>0</td><td>19558.0</td><td>18201.0</td><td>null</td><td>1</td><td>0.069903</td><td>0.069903</td><td>5.715302</td><td>5.715302</td><td>-40.174377</td><td>-40.174377</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>7.0</td><td>7.0</td><td>180.0</td><td>180.0</td><td>-2.0</td><td>-2.0</td><td>4.0</td><td>4.0</td><td>-290.0</td><td>-290.0</td><td>1.0</td><td>1.0</td><td>7.0</td><td>7.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td><td>&hellip;</td></tr><tr><td>9946</td><td>0</td><td>7</td><td>2</td><td>1</td><td>18274.0</td><td>18491.0</td><td>null</td><td>0</td><td>0.069903</td><td>0.069903</td><td>-3.284698</td><td>-3.284698</td><td>249.825623</td><td>249.825623</td><td>0.0</td><td>0.0</td><td>-3.0</td><td>-3.0</td><td>290.0</td><td>290.0</td><td>2.0</td><td>2.0</td><td>-2.0</td><td>-2.0</td><td>470.0</td><td>470.0</td><td>-2.0</td><td>-2.0</td><td>-5.0</td><td>-5.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>-2.0</td><td>-2.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9951</td><td>0</td><td>2</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-4.930097</td><td>-4.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-5.0</td><td>-5.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>-3.0</td><td>-3.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-7.0</td><td>-7.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-4.0</td><td>-4.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9952</td><td>1</td><td>10</td><td>4</td><td>0</td><td>18513.0</td><td>18201.0</td><td>null</td><td>1</td><td>3.069903</td><td>3.069903</td><td>-1.284698</td><td>-1.284698</td><td>-40.174377</td><td>-40.174377</td><td>3.0</td><td>3.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>5.0</td><td>0.0</td><td>0.0</td><td>180.0</td><td>180.0</td><td>1.0</td><td>1.0</td><td>-3.0</td><td>-3.0</td><td>-290.0</td><td>-290.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17182.038567</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16544.0</td><td>18513.0</td><td>2032.998426</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>18178.655096</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18472.0</td><td>611.61772</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9959</td><td>0</td><td>5</td><td>10</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>4.715302</td><td>4.715302</td><td>-985.174377</td><td>-985.174377</td><td>-2.0</td><td>-2.0</td><td>5.0</td><td>5.0</td><td>-945.0</td><td>-945.0</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>-765.0</td><td>-765.0</td><td>-4.0</td><td>-4.0</td><td>3.0</td><td>3.0</td><td>-1235.0</td><td>-1235.0</td><td>-1.0</td><td>-1.0</td><td>6.0</td><td>6.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9960</td><td>0</td><td>4</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-2.930097</td><td>-2.930097</td><td>-1.284698</td><td>-1.284698</td><td>-985.174377</td><td>-985.174377</td><td>-3.0</td><td>-3.0</td><td>-1.0</td><td>-1.0</td><td>-945.0</td><td>-945.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>-765.0</td><td>-765.0</td><td>-5.0</td><td>-5.0</td><td>-3.0</td><td>-3.0</td><td>-1235.0</td><td>-1235.0</td><td>-2.0</td><td>-2.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9964</td><td>1</td><td>4</td><td>6</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-2.930097</td><td>-2.930097</td><td>0.715302</td><td>0.715302</td><td>-985.174377</td><td>-985.174377</td><td>-3.0</td><td>-3.0</td><td>1.0</td><td>1.0</td><td>-945.0</td><td>-945.0</td><td>-1.0</td><td>-1.0</td><td>2.0</td><td>2.0</td><td>-765.0</td><td>-765.0</td><td>-5.0</td><td>-5.0</td><td>-1.0</td><td>-1.0</td><td>-1235.0</td><td>-1235.0</td><td>-2.0</td><td>-2.0</td><td>2.0</td><td>2.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9970</td><td>0</td><td>5</td><td>8</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-1.930097</td><td>-1.930097</td><td>2.715302</td><td>2.715302</td><td>-985.174377</td><td>-985.174377</td><td>-2.0</td><td>-2.0</td><td>3.0</td><td>3.0</td><td>-945.0</td><td>-945.0</td><td>0.0</td><td>0.0</td><td>4.0</td><td>4.0</td><td>-765.0</td><td>-765.0</td><td>-4.0</td><td>-4.0</td><td>1.0</td><td>1.0</td><td>-1235.0</td><td>-1235.0</td><td>-1.0</td><td>-1.0</td><td>4.0</td><td>4.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9971</td><td>0</td><td>6</td><td>3</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-0.930097</td><td>-0.930097</td><td>-2.284698</td><td>-2.284698</td><td>-985.174377</td><td>-985.174377</td><td>-1.0</td><td>-1.0</td><td>-2.0</td><td>-2.0</td><td>-945.0</td><td>-945.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>-765.0</td><td>-765.0</td><td>-3.0</td><td>-3.0</td><td>-4.0</td><td>-4.0</td><td>-1235.0</td><td>-1235.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9980</td><td>0</td><td>4</td><td>4</td><td>0</td><td>17409.0</td><td>17256.0</td><td>null</td><td>0</td><td>-2.930097</td><td>-2.930097</td><td>-1.284698</td><td>-1.284698</td><td>-985.174377</td><td>-985.174377</td><td>-3.0</td><td>-3.0</td><td>-1.0</td><td>-1.0</td><td>-945.0</td><td>-945.0</td><td>-1.0</td><td>-1.0</td><td>0.0</td><td>0.0</td><td>-765.0</td><td>-765.0</td><td>-5.0</td><td>-5.0</td><td>-3.0</td><td>-3.0</td><td>-1235.0</td><td>-1235.0</td><td>-2.0</td><td>-2.0</td><td>0.0</td><td>0.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr><tr><td>9983</td><td>1</td><td>6</td><td>3</td><td>1</td><td>18513.0</td><td>18201.0</td><td>null</td><td>0</td><td>-0.930097</td><td>-0.930097</td><td>-2.284698</td><td>-2.284698</td><td>-40.174377</td><td>-40.174377</td><td>-1.0</td><td>-1.0</td><td>-2.0</td><td>-2.0</td><td>0.0</td><td>0.0</td><td>1.0</td><td>1.0</td><td>-1.0</td><td>-1.0</td><td>180.0</td><td>180.0</td><td>-3.0</td><td>-3.0</td><td>-4.0</td><td>-4.0</td><td>-290.0</td><td>-290.0</td><td>0.0</td><td>0.0</td><td>-1.0</td><td>-1.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9996</td><td>1</td><td>10</td><td>9</td><td>1</td><td>18513.0</td><td>18201.0</td><td>null</td><td>0</td><td>3.069903</td><td>3.069903</td><td>3.715302</td><td>3.715302</td><td>-40.174377</td><td>-40.174377</td><td>3.0</td><td>3.0</td><td>4.0</td><td>4.0</td><td>0.0</td><td>0.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>5.0</td><td>180.0</td><td>180.0</td><td>1.0</td><td>1.0</td><td>2.0</td><td>2.0</td><td>-290.0</td><td>-290.0</td><td>4.0</td><td>4.0</td><td>5.0</td><td>5.0</td><td>&hellip;</td><td>18513.0</td><td>1965.603372</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>17604.678571</td><td>20619.0</td><td>13475.0</td><td>18274.0</td><td>16961.0</td><td>18513.0</td><td>1767.173224</td><td>18018.227334</td><td>20101.0</td><td>16650.0</td><td>18201.0</td><td>17256.0</td><td>18201.0</td><td>631.7526</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>18285.94894</td><td>20004.0</td><td>16650.0</td><td>18201.0</td><td>18021.0</td><td>18491.0</td><td>596.929256</td></tr><tr><td>9999</td><td>0</td><td>7</td><td>11</td><td>0</td><td>18117.0</td><td>18201.0</td><td>null</td><td>0</td><td>0.069903</td><td>0.069903</td><td>5.715302</td><td>5.715302</td><td>-40.174377</td><td>-40.174377</td><td>0.0</td><td>0.0</td><td>6.0</td><td>6.0</td><td>0.0</td><td>0.0</td><td>2.0</td><td>2.0</td><td>7.0</td><td>7.0</td><td>180.0</td><td>180.0</td><td>-2.0</td><td>-2.0</td><td>4.0</td><td>4.0</td><td>-290.0</td><td>-290.0</td><td>1.0</td><td>1.0</td><td>7.0</td><td>7.0</td><td>&hellip;</td><td>18117.0</td><td>1638.589312</td><td>17153.392901</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>16961.0</td><td>18274.0</td><td>1774.749883</td><td>16909.844451</td><td>20619.0</td><td>13475.0</td><td>17409.0</td><td>14536.0</td><td>17409.0</td><td>1809.092171</td><td>17954.679522</td><td>20004.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18472.0</td><td>895.453415</td><td>17944.3153</td><td>20101.0</td><td>16650.0</td><td>18021.0</td><td>17256.0</td><td>18472.0</td><td>796.824714</td><td>17820.649782</td><td>20101.0</td><td>16650.0</td><td>17256.0</td><td>17256.0</td><td>18201.0</td><td>807.047677</td></tr></tbody></table></div>"
      ],
      "text/plain": [
       "shape: (2_000, 153)\n",
       "┌────────┬────────────┬───────────┬────────────┬───┬───────────┬───────────┬───────────┬───────────┐\n",
       "│ gameId ┆ blueFirstB ┆ blueKills ┆ blueDeaths ┆ … ┆ blueTotal ┆ blueTotal ┆ blueTotal ┆ blueTotal │\n",
       "│ ---    ┆ lood       ┆ ---       ┆ ---        ┆   ┆ Experienc ┆ Experienc ┆ Experienc ┆ Experienc │\n",
       "│ i64    ┆ ---        ┆ i64       ┆ i64        ┆   ┆ e_blueDra ┆ e_blueDra ┆ e_blueDra ┆ e_blueDra │\n",
       "│        ┆ i64        ┆           ┆            ┆   ┆ gons_…    ┆ gons_…    ┆ gons_…    ┆ gons_…    │\n",
       "│        ┆            ┆           ┆            ┆   ┆ ---       ┆ ---       ┆ ---       ┆ ---       │\n",
       "│        ┆            ┆           ┆            ┆   ┆ f64       ┆ f64       ┆ f64       ┆ f64       │\n",
       "╞════════╪════════════╪═══════════╪════════════╪═══╪═══════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ 9      ┆ 0          ┆ 7         ┆ 6          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 15     ┆ 0          ┆ 6         ┆ 6          ┆ … ┆ 18201.0   ┆ 18021.0   ┆ 18491.0   ┆ 596.92925 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 18     ┆ 1          ┆ 6         ┆ 4          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 23     ┆ 0          ┆ 5         ┆ 4          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 31     ┆ 0          ┆ 10        ┆ 8          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ …      ┆ …          ┆ …         ┆ …          ┆ … ┆ …         ┆ …         ┆ …         ┆ …         │\n",
       "│ 9971   ┆ 0          ┆ 6         ┆ 3          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 9980   ┆ 0          ┆ 4         ┆ 4          ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "│ 9983   ┆ 1          ┆ 6         ┆ 3          ┆ … ┆ 18201.0   ┆ 18021.0   ┆ 18491.0   ┆ 596.92925 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 9996   ┆ 1          ┆ 10        ┆ 9          ┆ … ┆ 18201.0   ┆ 18021.0   ┆ 18491.0   ┆ 596.92925 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 6         │\n",
       "│ 9999   ┆ 0          ┆ 7         ┆ 11         ┆ … ┆ 17256.0   ┆ 17256.0   ┆ 18201.0   ┆ 807.04767 │\n",
       "│        ┆            ┆           ┆            ┆   ┆           ┆           ┆           ┆ 7         │\n",
       "└────────┴────────────┴───────────┴────────────┴───┴───────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycaret.classification import ClassificationExperiment\n",
    "\n",
    "exp = ClassificationExperiment()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_3f929_row9_col1, #T_3f929_row13_col1, #T_3f929_row15_col1, #T_3f929_row20_col1 {\n",
       "  background-color: lightgreen;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_3f929\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_3f929_level0_col0\" class=\"col_heading level0 col0\" >Description</th>\n",
       "      <th id=\"T_3f929_level0_col1\" class=\"col_heading level0 col1\" >Value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_3f929_row0_col0\" class=\"data row0 col0\" >Session id</td>\n",
       "      <td id=\"T_3f929_row0_col1\" class=\"data row0 col1\" >123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_3f929_row1_col0\" class=\"data row1 col0\" >Target</td>\n",
       "      <td id=\"T_3f929_row1_col1\" class=\"data row1 col1\" >blueWins</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_3f929_row2_col0\" class=\"data row2 col0\" >Target type</td>\n",
       "      <td id=\"T_3f929_row2_col1\" class=\"data row2 col1\" >Binary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_3f929_row3_col0\" class=\"data row3 col0\" >Original data shape</td>\n",
       "      <td id=\"T_3f929_row3_col1\" class=\"data row3 col1\" >(8000, 153)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_3f929_row4_col0\" class=\"data row4 col0\" >Transformed data shape</td>\n",
       "      <td id=\"T_3f929_row4_col1\" class=\"data row4 col1\" >(8000, 152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_3f929_row5_col0\" class=\"data row5 col0\" >Transformed train set shape</td>\n",
       "      <td id=\"T_3f929_row5_col1\" class=\"data row5 col1\" >(5600, 152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_3f929_row6_col0\" class=\"data row6 col0\" >Transformed test set shape</td>\n",
       "      <td id=\"T_3f929_row6_col1\" class=\"data row6 col1\" >(2400, 152)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_3f929_row7_col0\" class=\"data row7 col0\" >Ignore features</td>\n",
       "      <td id=\"T_3f929_row7_col1\" class=\"data row7 col1\" >1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_3f929_row8_col0\" class=\"data row8 col0\" >Numeric features</td>\n",
       "      <td id=\"T_3f929_row8_col1\" class=\"data row8 col1\" >151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_3f929_row9_col0\" class=\"data row9 col0\" >Preprocess</td>\n",
       "      <td id=\"T_3f929_row9_col1\" class=\"data row9 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row10\" class=\"row_heading level0 row10\" >10</th>\n",
       "      <td id=\"T_3f929_row10_col0\" class=\"data row10 col0\" >Imputation type</td>\n",
       "      <td id=\"T_3f929_row10_col1\" class=\"data row10 col1\" >simple</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row11\" class=\"row_heading level0 row11\" >11</th>\n",
       "      <td id=\"T_3f929_row11_col0\" class=\"data row11 col0\" >Numeric imputation</td>\n",
       "      <td id=\"T_3f929_row11_col1\" class=\"data row11 col1\" >mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row12\" class=\"row_heading level0 row12\" >12</th>\n",
       "      <td id=\"T_3f929_row12_col0\" class=\"data row12 col0\" >Categorical imputation</td>\n",
       "      <td id=\"T_3f929_row12_col1\" class=\"data row12 col1\" >mode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row13\" class=\"row_heading level0 row13\" >13</th>\n",
       "      <td id=\"T_3f929_row13_col0\" class=\"data row13 col0\" >Transformation</td>\n",
       "      <td id=\"T_3f929_row13_col1\" class=\"data row13 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row14\" class=\"row_heading level0 row14\" >14</th>\n",
       "      <td id=\"T_3f929_row14_col0\" class=\"data row14 col0\" >Transformation method</td>\n",
       "      <td id=\"T_3f929_row14_col1\" class=\"data row14 col1\" >yeo-johnson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row15\" class=\"row_heading level0 row15\" >15</th>\n",
       "      <td id=\"T_3f929_row15_col0\" class=\"data row15 col0\" >Normalize</td>\n",
       "      <td id=\"T_3f929_row15_col1\" class=\"data row15 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row16\" class=\"row_heading level0 row16\" >16</th>\n",
       "      <td id=\"T_3f929_row16_col0\" class=\"data row16 col0\" >Normalize method</td>\n",
       "      <td id=\"T_3f929_row16_col1\" class=\"data row16 col1\" >zscore</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row17\" class=\"row_heading level0 row17\" >17</th>\n",
       "      <td id=\"T_3f929_row17_col0\" class=\"data row17 col0\" >Fold Generator</td>\n",
       "      <td id=\"T_3f929_row17_col1\" class=\"data row17 col1\" >StratifiedKFold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row18\" class=\"row_heading level0 row18\" >18</th>\n",
       "      <td id=\"T_3f929_row18_col0\" class=\"data row18 col0\" >Fold Number</td>\n",
       "      <td id=\"T_3f929_row18_col1\" class=\"data row18 col1\" >10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row19\" class=\"row_heading level0 row19\" >19</th>\n",
       "      <td id=\"T_3f929_row19_col0\" class=\"data row19 col0\" >CPU Jobs</td>\n",
       "      <td id=\"T_3f929_row19_col1\" class=\"data row19 col1\" >-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row20\" class=\"row_heading level0 row20\" >20</th>\n",
       "      <td id=\"T_3f929_row20_col0\" class=\"data row20 col0\" >Use GPU</td>\n",
       "      <td id=\"T_3f929_row20_col1\" class=\"data row20 col1\" >True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row21\" class=\"row_heading level0 row21\" >21</th>\n",
       "      <td id=\"T_3f929_row21_col0\" class=\"data row21 col0\" >Log Experiment</td>\n",
       "      <td id=\"T_3f929_row21_col1\" class=\"data row21 col1\" >False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row22\" class=\"row_heading level0 row22\" >22</th>\n",
       "      <td id=\"T_3f929_row22_col0\" class=\"data row22 col0\" >Experiment Name</td>\n",
       "      <td id=\"T_3f929_row22_col1\" class=\"data row22 col1\" >clf-default-name</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_3f929_level0_row23\" class=\"row_heading level0 row23\" >23</th>\n",
       "      <td id=\"T_3f929_row23_col0\" class=\"data row23 col0\" >USI</td>\n",
       "      <td id=\"T_3f929_row23_col1\" class=\"data row23 col1\" >d669</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f6867fd3dc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] This is the GPU trainer!!\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Warning] There are no meaningful features which satisfy the provided configuration. Decreasing Dataset parameters min_data_in_bin or min_data_in_leaf and re-constructing Dataset might resolve this warning.\n",
      "[LightGBM] [Warning] Using sparse features with CUDA is currently not supported.\n",
      "[LightGBM] [Info] Number of positive: 1, number of negative: 1\n",
      "[LightGBM] [Info] Total Bins 0\n",
      "[LightGBM] [Info] Number of data points in the train set: 2, number of used features: 0\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500000 -> initscore=0.000000\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n",
      "[LightGBM] [Warning] Stopped training because there are no more leaves that meet the split requirements\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pycaret.classification.oop.ClassificationExperiment at 0x7f6a52556200>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.setup(\n",
    "    data=train_df.to_pandas(),\n",
    "    target=\"blueWins\",\n",
    "    ignore_features=[\"gameId\"],\n",
    "    session_id=123,\n",
    "    fold=10,\n",
    "    fold_shuffle=True,\n",
    "    # verbose=True,\n",
    "    use_gpu=True,\n",
    "    # polynomial_features=True,\n",
    "    # polynomial_degree=3,\n",
    "    transformation=True,\n",
    "    transformation_method=\"yeo-johnson\",\n",
    "    normalize=True,\n",
    "    normalize_method=\"zscore\",\n",
    "    # feature_selection=True,\n",
    "    # n_features_to_select=0.5,\n",
    "    # low_variance_threshold=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_82a92 th {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82a92_row0_col0, #T_82a92_row0_col4, #T_82a92_row1_col0, #T_82a92_row1_col1, #T_82a92_row1_col2, #T_82a92_row1_col3, #T_82a92_row1_col5, #T_82a92_row1_col6, #T_82a92_row1_col7, #T_82a92_row2_col0, #T_82a92_row2_col1, #T_82a92_row2_col2, #T_82a92_row2_col3, #T_82a92_row2_col4, #T_82a92_row2_col5, #T_82a92_row2_col6, #T_82a92_row2_col7, #T_82a92_row3_col0, #T_82a92_row3_col1, #T_82a92_row3_col2, #T_82a92_row3_col3, #T_82a92_row3_col4, #T_82a92_row3_col5, #T_82a92_row3_col6, #T_82a92_row3_col7, #T_82a92_row4_col0, #T_82a92_row4_col1, #T_82a92_row4_col2, #T_82a92_row4_col3, #T_82a92_row4_col4, #T_82a92_row4_col5, #T_82a92_row4_col6, #T_82a92_row4_col7, #T_82a92_row5_col0, #T_82a92_row5_col1, #T_82a92_row5_col2, #T_82a92_row5_col4, #T_82a92_row5_col5, #T_82a92_row5_col6, #T_82a92_row5_col7, #T_82a92_row6_col0, #T_82a92_row6_col1, #T_82a92_row6_col2, #T_82a92_row6_col3, #T_82a92_row6_col4, #T_82a92_row6_col5, #T_82a92_row6_col6, #T_82a92_row6_col7, #T_82a92_row7_col0, #T_82a92_row7_col1, #T_82a92_row7_col2, #T_82a92_row7_col3, #T_82a92_row7_col4, #T_82a92_row7_col5, #T_82a92_row7_col6, #T_82a92_row7_col7, #T_82a92_row8_col0, #T_82a92_row8_col1, #T_82a92_row8_col2, #T_82a92_row8_col3, #T_82a92_row8_col4, #T_82a92_row8_col5, #T_82a92_row8_col6, #T_82a92_row8_col7, #T_82a92_row9_col0, #T_82a92_row9_col1, #T_82a92_row9_col2, #T_82a92_row9_col3, #T_82a92_row9_col4, #T_82a92_row9_col5, #T_82a92_row9_col6, #T_82a92_row9_col7, #T_82a92_row10_col0, #T_82a92_row10_col1, #T_82a92_row10_col2, #T_82a92_row10_col3, #T_82a92_row10_col4, #T_82a92_row10_col5, #T_82a92_row10_col6, #T_82a92_row10_col7, #T_82a92_row11_col0, #T_82a92_row11_col1, #T_82a92_row11_col2, #T_82a92_row11_col3, #T_82a92_row11_col4, #T_82a92_row11_col5, #T_82a92_row11_col6, #T_82a92_row11_col7, #T_82a92_row12_col0, #T_82a92_row12_col1, #T_82a92_row12_col2, #T_82a92_row12_col3, #T_82a92_row12_col4, #T_82a92_row12_col5, #T_82a92_row12_col6, #T_82a92_row12_col7, #T_82a92_row13_col0, #T_82a92_row13_col1, #T_82a92_row13_col2, #T_82a92_row13_col3, #T_82a92_row13_col4, #T_82a92_row13_col5, #T_82a92_row13_col6, #T_82a92_row13_col7, #T_82a92_row14_col0, #T_82a92_row14_col1, #T_82a92_row14_col2, #T_82a92_row14_col3, #T_82a92_row14_col4, #T_82a92_row14_col5, #T_82a92_row14_col6, #T_82a92_row14_col7, #T_82a92_row15_col0, #T_82a92_row15_col1, #T_82a92_row15_col2, #T_82a92_row15_col3, #T_82a92_row15_col4, #T_82a92_row15_col5, #T_82a92_row15_col6, #T_82a92_row15_col7 {\n",
       "  text-align: left;\n",
       "}\n",
       "#T_82a92_row0_col1, #T_82a92_row0_col2, #T_82a92_row0_col3, #T_82a92_row0_col5, #T_82a92_row0_col6, #T_82a92_row0_col7, #T_82a92_row1_col4, #T_82a92_row5_col3 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "}\n",
       "#T_82a92_row0_col8, #T_82a92_row1_col8, #T_82a92_row2_col8, #T_82a92_row3_col8, #T_82a92_row4_col8, #T_82a92_row5_col8, #T_82a92_row6_col8, #T_82a92_row7_col8, #T_82a92_row8_col8, #T_82a92_row9_col8, #T_82a92_row10_col8, #T_82a92_row11_col8, #T_82a92_row12_col8, #T_82a92_row13_col8, #T_82a92_row14_col8 {\n",
       "  text-align: left;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "#T_82a92_row15_col8 {\n",
       "  text-align: left;\n",
       "  background-color: yellow;\n",
       "  background-color: lightgrey;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_82a92\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_82a92_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_82a92_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_82a92_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_82a92_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_82a92_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_82a92_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_82a92_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_82a92_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "      <th id=\"T_82a92_level0_col8\" class=\"col_heading level0 col8\" >TT (Sec)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row0\" class=\"row_heading level0 row0\" >catboost</th>\n",
       "      <td id=\"T_82a92_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_82a92_row0_col1\" class=\"data row0 col1\" >0.7791</td>\n",
       "      <td id=\"T_82a92_row0_col2\" class=\"data row0 col2\" >0.8662</td>\n",
       "      <td id=\"T_82a92_row0_col3\" class=\"data row0 col3\" >0.7898</td>\n",
       "      <td id=\"T_82a92_row0_col4\" class=\"data row0 col4\" >0.7679</td>\n",
       "      <td id=\"T_82a92_row0_col5\" class=\"data row0 col5\" >0.7785</td>\n",
       "      <td id=\"T_82a92_row0_col6\" class=\"data row0 col6\" >0.5583</td>\n",
       "      <td id=\"T_82a92_row0_col7\" class=\"data row0 col7\" >0.5588</td>\n",
       "      <td id=\"T_82a92_row0_col8\" class=\"data row0 col8\" >19.6620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row1\" class=\"row_heading level0 row1\" >lightgbm</th>\n",
       "      <td id=\"T_82a92_row1_col0\" class=\"data row1 col0\" >Light Gradient Boosting Machine</td>\n",
       "      <td id=\"T_82a92_row1_col1\" class=\"data row1 col1\" >0.7752</td>\n",
       "      <td id=\"T_82a92_row1_col2\" class=\"data row1 col2\" >0.8633</td>\n",
       "      <td id=\"T_82a92_row1_col3\" class=\"data row1 col3\" >0.7771</td>\n",
       "      <td id=\"T_82a92_row1_col4\" class=\"data row1 col4\" >0.7685</td>\n",
       "      <td id=\"T_82a92_row1_col5\" class=\"data row1 col5\" >0.7725</td>\n",
       "      <td id=\"T_82a92_row1_col6\" class=\"data row1 col6\" >0.5503</td>\n",
       "      <td id=\"T_82a92_row1_col7\" class=\"data row1 col7\" >0.5506</td>\n",
       "      <td id=\"T_82a92_row1_col8\" class=\"data row1 col8\" >1.6720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row2\" class=\"row_heading level0 row2\" >gbc</th>\n",
       "      <td id=\"T_82a92_row2_col0\" class=\"data row2 col0\" >Gradient Boosting Classifier</td>\n",
       "      <td id=\"T_82a92_row2_col1\" class=\"data row2 col1\" >0.7727</td>\n",
       "      <td id=\"T_82a92_row2_col2\" class=\"data row2 col2\" >0.8626</td>\n",
       "      <td id=\"T_82a92_row2_col3\" class=\"data row2 col3\" >0.7810</td>\n",
       "      <td id=\"T_82a92_row2_col4\" class=\"data row2 col4\" >0.7625</td>\n",
       "      <td id=\"T_82a92_row2_col5\" class=\"data row2 col5\" >0.7714</td>\n",
       "      <td id=\"T_82a92_row2_col6\" class=\"data row2 col6\" >0.5454</td>\n",
       "      <td id=\"T_82a92_row2_col7\" class=\"data row2 col7\" >0.5460</td>\n",
       "      <td id=\"T_82a92_row2_col8\" class=\"data row2 col8\" >1.9840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row3\" class=\"row_heading level0 row3\" >xgboost</th>\n",
       "      <td id=\"T_82a92_row3_col0\" class=\"data row3 col0\" >Extreme Gradient Boosting</td>\n",
       "      <td id=\"T_82a92_row3_col1\" class=\"data row3 col1\" >0.7698</td>\n",
       "      <td id=\"T_82a92_row3_col2\" class=\"data row3 col2\" >0.8526</td>\n",
       "      <td id=\"T_82a92_row3_col3\" class=\"data row3 col3\" >0.7691</td>\n",
       "      <td id=\"T_82a92_row3_col4\" class=\"data row3 col4\" >0.7646</td>\n",
       "      <td id=\"T_82a92_row3_col5\" class=\"data row3 col5\" >0.7666</td>\n",
       "      <td id=\"T_82a92_row3_col6\" class=\"data row3 col6\" >0.5396</td>\n",
       "      <td id=\"T_82a92_row3_col7\" class=\"data row3 col7\" >0.5399</td>\n",
       "      <td id=\"T_82a92_row3_col8\" class=\"data row3 col8\" >0.9280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row4\" class=\"row_heading level0 row4\" >ada</th>\n",
       "      <td id=\"T_82a92_row4_col0\" class=\"data row4 col0\" >Ada Boost Classifier</td>\n",
       "      <td id=\"T_82a92_row4_col1\" class=\"data row4 col1\" >0.7657</td>\n",
       "      <td id=\"T_82a92_row4_col2\" class=\"data row4 col2\" >0.8563</td>\n",
       "      <td id=\"T_82a92_row4_col3\" class=\"data row4 col3\" >0.7738</td>\n",
       "      <td id=\"T_82a92_row4_col4\" class=\"data row4 col4\" >0.7559</td>\n",
       "      <td id=\"T_82a92_row4_col5\" class=\"data row4 col5\" >0.7646</td>\n",
       "      <td id=\"T_82a92_row4_col6\" class=\"data row4 col6\" >0.5315</td>\n",
       "      <td id=\"T_82a92_row4_col7\" class=\"data row4 col7\" >0.5319</td>\n",
       "      <td id=\"T_82a92_row4_col8\" class=\"data row4 col8\" >1.0290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row5\" class=\"row_heading level0 row5\" >lda</th>\n",
       "      <td id=\"T_82a92_row5_col0\" class=\"data row5 col0\" >Linear Discriminant Analysis</td>\n",
       "      <td id=\"T_82a92_row5_col1\" class=\"data row5 col1\" >0.7580</td>\n",
       "      <td id=\"T_82a92_row5_col2\" class=\"data row5 col2\" >0.8241</td>\n",
       "      <td id=\"T_82a92_row5_col3\" class=\"data row5 col3\" >0.7898</td>\n",
       "      <td id=\"T_82a92_row5_col4\" class=\"data row5 col4\" >0.7370</td>\n",
       "      <td id=\"T_82a92_row5_col5\" class=\"data row5 col5\" >0.7624</td>\n",
       "      <td id=\"T_82a92_row5_col6\" class=\"data row5 col6\" >0.5165</td>\n",
       "      <td id=\"T_82a92_row5_col7\" class=\"data row5 col7\" >0.5180</td>\n",
       "      <td id=\"T_82a92_row5_col8\" class=\"data row5 col8\" >0.6940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row6\" class=\"row_heading level0 row6\" >ridge</th>\n",
       "      <td id=\"T_82a92_row6_col0\" class=\"data row6 col0\" >Ridge Classifier</td>\n",
       "      <td id=\"T_82a92_row6_col1\" class=\"data row6 col1\" >0.7579</td>\n",
       "      <td id=\"T_82a92_row6_col2\" class=\"data row6 col2\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row6_col3\" class=\"data row6 col3\" >0.7876</td>\n",
       "      <td id=\"T_82a92_row6_col4\" class=\"data row6 col4\" >0.7378</td>\n",
       "      <td id=\"T_82a92_row6_col5\" class=\"data row6 col5\" >0.7617</td>\n",
       "      <td id=\"T_82a92_row6_col6\" class=\"data row6 col6\" >0.5161</td>\n",
       "      <td id=\"T_82a92_row6_col7\" class=\"data row6 col7\" >0.5175</td>\n",
       "      <td id=\"T_82a92_row6_col8\" class=\"data row6 col8\" >0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row7\" class=\"row_heading level0 row7\" >lr</th>\n",
       "      <td id=\"T_82a92_row7_col0\" class=\"data row7 col0\" >Logistic Regression</td>\n",
       "      <td id=\"T_82a92_row7_col1\" class=\"data row7 col1\" >0.7561</td>\n",
       "      <td id=\"T_82a92_row7_col2\" class=\"data row7 col2\" >0.8180</td>\n",
       "      <td id=\"T_82a92_row7_col3\" class=\"data row7 col3\" >0.7803</td>\n",
       "      <td id=\"T_82a92_row7_col4\" class=\"data row7 col4\" >0.7387</td>\n",
       "      <td id=\"T_82a92_row7_col5\" class=\"data row7 col5\" >0.7587</td>\n",
       "      <td id=\"T_82a92_row7_col6\" class=\"data row7 col6\" >0.5125</td>\n",
       "      <td id=\"T_82a92_row7_col7\" class=\"data row7 col7\" >0.5135</td>\n",
       "      <td id=\"T_82a92_row7_col8\" class=\"data row7 col8\" >0.7350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row8\" class=\"row_heading level0 row8\" >rf</th>\n",
       "      <td id=\"T_82a92_row8_col0\" class=\"data row8 col0\" >Random Forest Classifier</td>\n",
       "      <td id=\"T_82a92_row8_col1\" class=\"data row8 col1\" >0.7334</td>\n",
       "      <td id=\"T_82a92_row8_col2\" class=\"data row8 col2\" >0.8145</td>\n",
       "      <td id=\"T_82a92_row8_col3\" class=\"data row8 col3\" >0.7146</td>\n",
       "      <td id=\"T_82a92_row8_col4\" class=\"data row8 col4\" >0.7361</td>\n",
       "      <td id=\"T_82a92_row8_col5\" class=\"data row8 col5\" >0.7248</td>\n",
       "      <td id=\"T_82a92_row8_col6\" class=\"data row8 col6\" >0.4664</td>\n",
       "      <td id=\"T_82a92_row8_col7\" class=\"data row8 col7\" >0.4670</td>\n",
       "      <td id=\"T_82a92_row8_col8\" class=\"data row8 col8\" >0.9180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row9\" class=\"row_heading level0 row9\" >knn</th>\n",
       "      <td id=\"T_82a92_row9_col0\" class=\"data row9 col0\" >K Neighbors Classifier</td>\n",
       "      <td id=\"T_82a92_row9_col1\" class=\"data row9 col1\" >0.7263</td>\n",
       "      <td id=\"T_82a92_row9_col2\" class=\"data row9 col2\" >0.7942</td>\n",
       "      <td id=\"T_82a92_row9_col3\" class=\"data row9 col3\" >0.7317</td>\n",
       "      <td id=\"T_82a92_row9_col4\" class=\"data row9 col4\" >0.7176</td>\n",
       "      <td id=\"T_82a92_row9_col5\" class=\"data row9 col5\" >0.7243</td>\n",
       "      <td id=\"T_82a92_row9_col6\" class=\"data row9 col6\" >0.4525</td>\n",
       "      <td id=\"T_82a92_row9_col7\" class=\"data row9 col7\" >0.4529</td>\n",
       "      <td id=\"T_82a92_row9_col8\" class=\"data row9 col8\" >0.6570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row10\" class=\"row_heading level0 row10\" >et</th>\n",
       "      <td id=\"T_82a92_row10_col0\" class=\"data row10 col0\" >Extra Trees Classifier</td>\n",
       "      <td id=\"T_82a92_row10_col1\" class=\"data row10 col1\" >0.7241</td>\n",
       "      <td id=\"T_82a92_row10_col2\" class=\"data row10 col2\" >0.7741</td>\n",
       "      <td id=\"T_82a92_row10_col3\" class=\"data row10 col3\" >0.6859</td>\n",
       "      <td id=\"T_82a92_row10_col4\" class=\"data row10 col4\" >0.7356</td>\n",
       "      <td id=\"T_82a92_row10_col5\" class=\"data row10 col5\" >0.7095</td>\n",
       "      <td id=\"T_82a92_row10_col6\" class=\"data row10 col6\" >0.4475</td>\n",
       "      <td id=\"T_82a92_row10_col7\" class=\"data row10 col7\" >0.4489</td>\n",
       "      <td id=\"T_82a92_row10_col8\" class=\"data row10 col8\" >0.8880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row11\" class=\"row_heading level0 row11\" >dt</th>\n",
       "      <td id=\"T_82a92_row11_col0\" class=\"data row11 col0\" >Decision Tree Classifier</td>\n",
       "      <td id=\"T_82a92_row11_col1\" class=\"data row11 col1\" >0.7213</td>\n",
       "      <td id=\"T_82a92_row11_col2\" class=\"data row11 col2\" >0.7267</td>\n",
       "      <td id=\"T_82a92_row11_col3\" class=\"data row11 col3\" >0.6700</td>\n",
       "      <td id=\"T_82a92_row11_col4\" class=\"data row11 col4\" >0.7390</td>\n",
       "      <td id=\"T_82a92_row11_col5\" class=\"data row11 col5\" >0.7022</td>\n",
       "      <td id=\"T_82a92_row11_col6\" class=\"data row11 col6\" >0.4415</td>\n",
       "      <td id=\"T_82a92_row11_col7\" class=\"data row11 col7\" >0.4439</td>\n",
       "      <td id=\"T_82a92_row11_col8\" class=\"data row11 col8\" >0.6650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row12\" class=\"row_heading level0 row12\" >nb</th>\n",
       "      <td id=\"T_82a92_row12_col0\" class=\"data row12 col0\" >Naive Bayes</td>\n",
       "      <td id=\"T_82a92_row12_col1\" class=\"data row12 col1\" >0.7075</td>\n",
       "      <td id=\"T_82a92_row12_col2\" class=\"data row12 col2\" >0.7853</td>\n",
       "      <td id=\"T_82a92_row12_col3\" class=\"data row12 col3\" >0.6101</td>\n",
       "      <td id=\"T_82a92_row12_col4\" class=\"data row12 col4\" >0.7488</td>\n",
       "      <td id=\"T_82a92_row12_col5\" class=\"data row12 col5\" >0.6719</td>\n",
       "      <td id=\"T_82a92_row12_col6\" class=\"data row12 col6\" >0.4131</td>\n",
       "      <td id=\"T_82a92_row12_col7\" class=\"data row12 col7\" >0.4205</td>\n",
       "      <td id=\"T_82a92_row12_col8\" class=\"data row12 col8\" >0.6020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row13\" class=\"row_heading level0 row13\" >svm</th>\n",
       "      <td id=\"T_82a92_row13_col0\" class=\"data row13 col0\" >SVM - Linear Kernel</td>\n",
       "      <td id=\"T_82a92_row13_col1\" class=\"data row13 col1\" >0.6945</td>\n",
       "      <td id=\"T_82a92_row13_col2\" class=\"data row13 col2\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row13_col3\" class=\"data row13 col3\" >0.6968</td>\n",
       "      <td id=\"T_82a92_row13_col4\" class=\"data row13 col4\" >0.6878</td>\n",
       "      <td id=\"T_82a92_row13_col5\" class=\"data row13 col5\" >0.6904</td>\n",
       "      <td id=\"T_82a92_row13_col6\" class=\"data row13 col6\" >0.3889</td>\n",
       "      <td id=\"T_82a92_row13_col7\" class=\"data row13 col7\" >0.3911</td>\n",
       "      <td id=\"T_82a92_row13_col8\" class=\"data row13 col8\" >0.7240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row14\" class=\"row_heading level0 row14\" >qda</th>\n",
       "      <td id=\"T_82a92_row14_col0\" class=\"data row14 col0\" >Quadratic Discriminant Analysis</td>\n",
       "      <td id=\"T_82a92_row14_col1\" class=\"data row14 col1\" >0.6720</td>\n",
       "      <td id=\"T_82a92_row14_col2\" class=\"data row14 col2\" >0.6711</td>\n",
       "      <td id=\"T_82a92_row14_col3\" class=\"data row14 col3\" >0.6166</td>\n",
       "      <td id=\"T_82a92_row14_col4\" class=\"data row14 col4\" >0.6894</td>\n",
       "      <td id=\"T_82a92_row14_col5\" class=\"data row14 col5\" >0.6449</td>\n",
       "      <td id=\"T_82a92_row14_col6\" class=\"data row14 col6\" >0.3426</td>\n",
       "      <td id=\"T_82a92_row14_col7\" class=\"data row14 col7\" >0.3487</td>\n",
       "      <td id=\"T_82a92_row14_col8\" class=\"data row14 col8\" >0.6710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_82a92_level0_row15\" class=\"row_heading level0 row15\" >dummy</th>\n",
       "      <td id=\"T_82a92_row15_col0\" class=\"data row15 col0\" >Dummy Classifier</td>\n",
       "      <td id=\"T_82a92_row15_col1\" class=\"data row15 col1\" >0.5082</td>\n",
       "      <td id=\"T_82a92_row15_col2\" class=\"data row15 col2\" >0.5000</td>\n",
       "      <td id=\"T_82a92_row15_col3\" class=\"data row15 col3\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row15_col4\" class=\"data row15 col4\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row15_col5\" class=\"data row15 col5\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row15_col6\" class=\"data row15 col6\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row15_col7\" class=\"data row15 col7\" >0.0000</td>\n",
       "      <td id=\"T_82a92_row15_col8\" class=\"data row15 col8\" >0.5920</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f685c54e0b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "best = exp.compare_models(\n",
    "    sort=\"Accuracy\",\n",
    "    n_select=1,\n",
    "    # exclude=[\"catboost\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.plot_model(best, plot=\"feature\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_44a88\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_44a88_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_44a88_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_44a88_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_44a88_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_44a88_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_44a88_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_44a88_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_44a88_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_44a88_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_44a88_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_44a88_row0_col1\" class=\"data row0 col1\" >0.7942</td>\n",
       "      <td id=\"T_44a88_row0_col2\" class=\"data row0 col2\" >0.8734</td>\n",
       "      <td id=\"T_44a88_row0_col3\" class=\"data row0 col3\" >0.8068</td>\n",
       "      <td id=\"T_44a88_row0_col4\" class=\"data row0 col4\" >0.7816</td>\n",
       "      <td id=\"T_44a88_row0_col5\" class=\"data row0 col5\" >0.7940</td>\n",
       "      <td id=\"T_44a88_row0_col6\" class=\"data row0 col6\" >0.5884</td>\n",
       "      <td id=\"T_44a88_row0_col7\" class=\"data row0 col7\" >0.5887</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f688db313c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueTotalExperience</th>\n",
       "      <th>blueHerald</th>\n",
       "      <th>blueKills_win_mean_diff</th>\n",
       "      <th>blueKills_lose_mean_diff</th>\n",
       "      <th>blueDeaths_win_mean_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>blueTotalExperience_blueDragons_mean</th>\n",
       "      <th>blueTotalExperience_blueDragons_max</th>\n",
       "      <th>blueTotalExperience_blueDragons_min</th>\n",
       "      <th>blueTotalExperience_blueDragons_median</th>\n",
       "      <th>blueTotalExperience_blueDragons_q25</th>\n",
       "      <th>blueTotalExperience_blueDragons_q75</th>\n",
       "      <th>blueTotalExperience_blueDragons_std</th>\n",
       "      <th>blueWins</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.930097</td>\n",
       "      <td>-6.930097</td>\n",
       "      <td>2.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-1.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16961.0</td>\n",
       "      <td>18472.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>4.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>6.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9846</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19558.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.069903</td>\n",
       "      <td>2.069903</td>\n",
       "      <td>-0.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18513.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>-1.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8521</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      blueFirstBlood  blueKills  blueDeaths  blueDragons  blueTotalGold  \\\n",
       "4192               0          0           8            0        17409.0   \n",
       "933                0          6           6            0        20619.0   \n",
       "353                0          4           4            0        18117.0   \n",
       "3469               0          7           6            0        18117.0   \n",
       "2755               0          5           6            0        17409.0   \n",
       "...              ...        ...         ...          ...            ...   \n",
       "2411               0          5           6            1        16961.0   \n",
       "6017               0          6          10            0        20619.0   \n",
       "4257               0          4          12            0        17409.0   \n",
       "6028               1          9           5            1        19558.0   \n",
       "2947               1          7           4            0        18513.0   \n",
       "\n",
       "      blueTotalExperience  blueHerald  blueKills_win_mean_diff  \\\n",
       "4192              17256.0           0                -6.930097   \n",
       "933               17256.0           0                -0.930097   \n",
       "353               18201.0           0                -2.930097   \n",
       "3469              18491.0           0                 0.069903   \n",
       "2755              17256.0           0                -1.930097   \n",
       "...                   ...         ...                      ...   \n",
       "2411              18472.0           0                -1.930097   \n",
       "6017              17256.0           1                -0.930097   \n",
       "4257              17256.0           0                -2.930097   \n",
       "6028              18201.0           0                 2.069903   \n",
       "2947              18201.0           1                 0.069903   \n",
       "\n",
       "      blueKills_lose_mean_diff  blueDeaths_win_mean_diff  ...  \\\n",
       "4192                 -6.930097                  2.715302  ...   \n",
       "933                  -0.930097                  0.715302  ...   \n",
       "353                  -2.930097                 -1.284698  ...   \n",
       "3469                  0.069903                  0.715302  ...   \n",
       "2755                 -1.930097                  0.715302  ...   \n",
       "...                        ...                       ...  ...   \n",
       "2411                 -1.930097                  0.715302  ...   \n",
       "6017                 -0.930097                  4.715302  ...   \n",
       "4257                 -2.930097                  6.715302  ...   \n",
       "6028                  2.069903                 -0.284698  ...   \n",
       "2947                  0.069903                 -1.284698  ...   \n",
       "\n",
       "      blueTotalExperience_blueDragons_mean  \\\n",
       "4192                          17820.650391   \n",
       "933                           17820.650391   \n",
       "353                           17820.650391   \n",
       "3469                          17820.650391   \n",
       "2755                          17820.650391   \n",
       "...                                    ...   \n",
       "2411                          18285.949219   \n",
       "6017                          17820.650391   \n",
       "4257                          17820.650391   \n",
       "6028                          18285.949219   \n",
       "2947                          17820.650391   \n",
       "\n",
       "      blueTotalExperience_blueDragons_max  \\\n",
       "4192                              20101.0   \n",
       "933                               20101.0   \n",
       "353                               20101.0   \n",
       "3469                              20101.0   \n",
       "2755                              20101.0   \n",
       "...                                   ...   \n",
       "2411                              20004.0   \n",
       "6017                              20101.0   \n",
       "4257                              20101.0   \n",
       "6028                              20004.0   \n",
       "2947                              20101.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_min  \\\n",
       "4192                              16650.0   \n",
       "933                               16650.0   \n",
       "353                               16650.0   \n",
       "3469                              16650.0   \n",
       "2755                              16650.0   \n",
       "...                                   ...   \n",
       "2411                              16650.0   \n",
       "6017                              16650.0   \n",
       "4257                              16650.0   \n",
       "6028                              16650.0   \n",
       "2947                              16650.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_median  \\\n",
       "4192                                 17256.0   \n",
       "933                                  17256.0   \n",
       "353                                  17256.0   \n",
       "3469                                 17256.0   \n",
       "2755                                 17256.0   \n",
       "...                                      ...   \n",
       "2411                                 18201.0   \n",
       "6017                                 17256.0   \n",
       "4257                                 17256.0   \n",
       "6028                                 18201.0   \n",
       "2947                                 17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q25  \\\n",
       "4192                              17256.0   \n",
       "933                               17256.0   \n",
       "353                               17256.0   \n",
       "3469                              17256.0   \n",
       "2755                              17256.0   \n",
       "...                                   ...   \n",
       "2411                              18021.0   \n",
       "6017                              17256.0   \n",
       "4257                              17256.0   \n",
       "6028                              18021.0   \n",
       "2947                              17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q75  \\\n",
       "4192                              18201.0   \n",
       "933                               18201.0   \n",
       "353                               18201.0   \n",
       "3469                              18201.0   \n",
       "2755                              18201.0   \n",
       "...                                   ...   \n",
       "2411                              18491.0   \n",
       "6017                              18201.0   \n",
       "4257                              18201.0   \n",
       "6028                              18491.0   \n",
       "2947                              18201.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_std  blueWins  prediction_label  \\\n",
       "4192                           807.047668         0                 0   \n",
       "933                            807.047668         0                 0   \n",
       "353                            807.047668         1                 1   \n",
       "3469                           807.047668         1                 1   \n",
       "2755                           807.047668         0                 0   \n",
       "...                                   ...       ...               ...   \n",
       "2411                           596.929260         0                 1   \n",
       "6017                           807.047668         0                 0   \n",
       "4257                           807.047668         0                 0   \n",
       "6028                           596.929260         1                 1   \n",
       "2947                           807.047668         1                 1   \n",
       "\n",
       "      prediction_score  \n",
       "4192            0.9390  \n",
       "933             0.6921  \n",
       "353             0.6868  \n",
       "3469            0.7148  \n",
       "2755            0.9151  \n",
       "...                ...  \n",
       "2411            0.6222  \n",
       "6017            0.8639  \n",
       "4257            0.9846  \n",
       "6028            0.5900  \n",
       "2947            0.8521  \n",
       "\n",
       "[2400 rows x 154 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.predict_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b3644bcdbcd4221aecc3737959bfbbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(ToggleButtons(description='Plot Type:', icons=('',), options=(('Pipeline Plot', 'pipelin…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp.evaluate_model(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "#T_00754_row10_col0, #T_00754_row10_col1, #T_00754_row10_col2, #T_00754_row10_col3, #T_00754_row10_col4, #T_00754_row10_col5, #T_00754_row10_col6 {\n",
       "  background: yellow;\n",
       "}\n",
       "</style>\n",
       "<table id=\"T_00754\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_00754_level0_col0\" class=\"col_heading level0 col0\" >Accuracy</th>\n",
       "      <th id=\"T_00754_level0_col1\" class=\"col_heading level0 col1\" >AUC</th>\n",
       "      <th id=\"T_00754_level0_col2\" class=\"col_heading level0 col2\" >Recall</th>\n",
       "      <th id=\"T_00754_level0_col3\" class=\"col_heading level0 col3\" >Prec.</th>\n",
       "      <th id=\"T_00754_level0_col4\" class=\"col_heading level0 col4\" >F1</th>\n",
       "      <th id=\"T_00754_level0_col5\" class=\"col_heading level0 col5\" >Kappa</th>\n",
       "      <th id=\"T_00754_level0_col6\" class=\"col_heading level0 col6\" >MCC</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th class=\"index_name level0\" >Fold</th>\n",
       "      <th class=\"blank col0\" >&nbsp;</th>\n",
       "      <th class=\"blank col1\" >&nbsp;</th>\n",
       "      <th class=\"blank col2\" >&nbsp;</th>\n",
       "      <th class=\"blank col3\" >&nbsp;</th>\n",
       "      <th class=\"blank col4\" >&nbsp;</th>\n",
       "      <th class=\"blank col5\" >&nbsp;</th>\n",
       "      <th class=\"blank col6\" >&nbsp;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_00754_row0_col0\" class=\"data row0 col0\" >0.7982</td>\n",
       "      <td id=\"T_00754_row0_col1\" class=\"data row0 col1\" >0.8697</td>\n",
       "      <td id=\"T_00754_row0_col2\" class=\"data row0 col2\" >0.8188</td>\n",
       "      <td id=\"T_00754_row0_col3\" class=\"data row0 col3\" >0.7820</td>\n",
       "      <td id=\"T_00754_row0_col4\" class=\"data row0 col4\" >0.8000</td>\n",
       "      <td id=\"T_00754_row0_col5\" class=\"data row0 col5\" >0.5966</td>\n",
       "      <td id=\"T_00754_row0_col6\" class=\"data row0 col6\" >0.5973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row1\" class=\"row_heading level0 row1\" >1</th>\n",
       "      <td id=\"T_00754_row1_col0\" class=\"data row1 col0\" >0.7536</td>\n",
       "      <td id=\"T_00754_row1_col1\" class=\"data row1 col1\" >0.8336</td>\n",
       "      <td id=\"T_00754_row1_col2\" class=\"data row1 col2\" >0.8007</td>\n",
       "      <td id=\"T_00754_row1_col3\" class=\"data row1 col3\" >0.7270</td>\n",
       "      <td id=\"T_00754_row1_col4\" class=\"data row1 col4\" >0.7621</td>\n",
       "      <td id=\"T_00754_row1_col5\" class=\"data row1 col5\" >0.5077</td>\n",
       "      <td id=\"T_00754_row1_col6\" class=\"data row1 col6\" >0.5103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row2\" class=\"row_heading level0 row2\" >2</th>\n",
       "      <td id=\"T_00754_row2_col0\" class=\"data row2 col0\" >0.7875</td>\n",
       "      <td id=\"T_00754_row2_col1\" class=\"data row2 col1\" >0.8727</td>\n",
       "      <td id=\"T_00754_row2_col2\" class=\"data row2 col2\" >0.8333</td>\n",
       "      <td id=\"T_00754_row2_col3\" class=\"data row2 col3\" >0.7591</td>\n",
       "      <td id=\"T_00754_row2_col4\" class=\"data row2 col4\" >0.7945</td>\n",
       "      <td id=\"T_00754_row2_col5\" class=\"data row2 col5\" >0.5755</td>\n",
       "      <td id=\"T_00754_row2_col6\" class=\"data row2 col6\" >0.5782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row3\" class=\"row_heading level0 row3\" >3</th>\n",
       "      <td id=\"T_00754_row3_col0\" class=\"data row3 col0\" >0.7696</td>\n",
       "      <td id=\"T_00754_row3_col1\" class=\"data row3 col1\" >0.8658</td>\n",
       "      <td id=\"T_00754_row3_col2\" class=\"data row3 col2\" >0.7790</td>\n",
       "      <td id=\"T_00754_row3_col3\" class=\"data row3 col3\" >0.7597</td>\n",
       "      <td id=\"T_00754_row3_col4\" class=\"data row3 col4\" >0.7692</td>\n",
       "      <td id=\"T_00754_row3_col5\" class=\"data row3 col5\" >0.5394</td>\n",
       "      <td id=\"T_00754_row3_col6\" class=\"data row3 col6\" >0.5395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row4\" class=\"row_heading level0 row4\" >4</th>\n",
       "      <td id=\"T_00754_row4_col0\" class=\"data row4 col0\" >0.7696</td>\n",
       "      <td id=\"T_00754_row4_col1\" class=\"data row4 col1\" >0.8603</td>\n",
       "      <td id=\"T_00754_row4_col2\" class=\"data row4 col2\" >0.8327</td>\n",
       "      <td id=\"T_00754_row4_col3\" class=\"data row4 col3\" >0.7340</td>\n",
       "      <td id=\"T_00754_row4_col4\" class=\"data row4 col4\" >0.7802</td>\n",
       "      <td id=\"T_00754_row4_col5\" class=\"data row4 col5\" >0.5402</td>\n",
       "      <td id=\"T_00754_row4_col6\" class=\"data row4 col6\" >0.5450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row5\" class=\"row_heading level0 row5\" >5</th>\n",
       "      <td id=\"T_00754_row5_col0\" class=\"data row5 col0\" >0.7625</td>\n",
       "      <td id=\"T_00754_row5_col1\" class=\"data row5 col1\" >0.8588</td>\n",
       "      <td id=\"T_00754_row5_col2\" class=\"data row5 col2\" >0.8000</td>\n",
       "      <td id=\"T_00754_row5_col3\" class=\"data row5 col3\" >0.7383</td>\n",
       "      <td id=\"T_00754_row5_col4\" class=\"data row5 col4\" >0.7679</td>\n",
       "      <td id=\"T_00754_row5_col5\" class=\"data row5 col5\" >0.5255</td>\n",
       "      <td id=\"T_00754_row5_col6\" class=\"data row5 col6\" >0.5273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row6\" class=\"row_heading level0 row6\" >6</th>\n",
       "      <td id=\"T_00754_row6_col0\" class=\"data row6 col0\" >0.7429</td>\n",
       "      <td id=\"T_00754_row6_col1\" class=\"data row6 col1\" >0.8369</td>\n",
       "      <td id=\"T_00754_row6_col2\" class=\"data row6 col2\" >0.7345</td>\n",
       "      <td id=\"T_00754_row6_col3\" class=\"data row6 col3\" >0.7399</td>\n",
       "      <td id=\"T_00754_row6_col4\" class=\"data row6 col4\" >0.7372</td>\n",
       "      <td id=\"T_00754_row6_col5\" class=\"data row6 col5\" >0.4855</td>\n",
       "      <td id=\"T_00754_row6_col6\" class=\"data row6 col6\" >0.4855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row7\" class=\"row_heading level0 row7\" >7</th>\n",
       "      <td id=\"T_00754_row7_col0\" class=\"data row7 col0\" >0.7536</td>\n",
       "      <td id=\"T_00754_row7_col1\" class=\"data row7 col1\" >0.8354</td>\n",
       "      <td id=\"T_00754_row7_col2\" class=\"data row7 col2\" >0.8109</td>\n",
       "      <td id=\"T_00754_row7_col3\" class=\"data row7 col3\" >0.7217</td>\n",
       "      <td id=\"T_00754_row7_col4\" class=\"data row7 col4\" >0.7637</td>\n",
       "      <td id=\"T_00754_row7_col5\" class=\"data row7 col5\" >0.5081</td>\n",
       "      <td id=\"T_00754_row7_col6\" class=\"data row7 col6\" >0.5118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row8\" class=\"row_heading level0 row8\" >8</th>\n",
       "      <td id=\"T_00754_row8_col0\" class=\"data row8 col0\" >0.7607</td>\n",
       "      <td id=\"T_00754_row8_col1\" class=\"data row8 col1\" >0.8458</td>\n",
       "      <td id=\"T_00754_row8_col2\" class=\"data row8 col2\" >0.7964</td>\n",
       "      <td id=\"T_00754_row8_col3\" class=\"data row8 col3\" >0.7374</td>\n",
       "      <td id=\"T_00754_row8_col4\" class=\"data row8 col4\" >0.7657</td>\n",
       "      <td id=\"T_00754_row8_col5\" class=\"data row8 col5\" >0.5219</td>\n",
       "      <td id=\"T_00754_row8_col6\" class=\"data row8 col6\" >0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row9\" class=\"row_heading level0 row9\" >9</th>\n",
       "      <td id=\"T_00754_row9_col0\" class=\"data row9 col0\" >0.7589</td>\n",
       "      <td id=\"T_00754_row9_col1\" class=\"data row9 col1\" >0.8425</td>\n",
       "      <td id=\"T_00754_row9_col2\" class=\"data row9 col2\" >0.7891</td>\n",
       "      <td id=\"T_00754_row9_col3\" class=\"data row9 col3\" >0.7381</td>\n",
       "      <td id=\"T_00754_row9_col4\" class=\"data row9 col4\" >0.7627</td>\n",
       "      <td id=\"T_00754_row9_col5\" class=\"data row9 col5\" >0.5183</td>\n",
       "      <td id=\"T_00754_row9_col6\" class=\"data row9 col6\" >0.5195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row10\" class=\"row_heading level0 row10\" >Mean</th>\n",
       "      <td id=\"T_00754_row10_col0\" class=\"data row10 col0\" >0.7657</td>\n",
       "      <td id=\"T_00754_row10_col1\" class=\"data row10 col1\" >0.8521</td>\n",
       "      <td id=\"T_00754_row10_col2\" class=\"data row10 col2\" >0.7996</td>\n",
       "      <td id=\"T_00754_row10_col3\" class=\"data row10 col3\" >0.7437</td>\n",
       "      <td id=\"T_00754_row10_col4\" class=\"data row10 col4\" >0.7703</td>\n",
       "      <td id=\"T_00754_row10_col5\" class=\"data row10 col5\" >0.5319</td>\n",
       "      <td id=\"T_00754_row10_col6\" class=\"data row10 col6\" >0.5338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th id=\"T_00754_level0_row11\" class=\"row_heading level0 row11\" >Std</th>\n",
       "      <td id=\"T_00754_row11_col0\" class=\"data row11 col0\" >0.0157</td>\n",
       "      <td id=\"T_00754_row11_col1\" class=\"data row11 col1\" >0.0142</td>\n",
       "      <td id=\"T_00754_row11_col2\" class=\"data row11 col2\" >0.0274</td>\n",
       "      <td id=\"T_00754_row11_col3\" class=\"data row11 col3\" >0.0171</td>\n",
       "      <td id=\"T_00754_row11_col4\" class=\"data row11 col4\" >0.0169</td>\n",
       "      <td id=\"T_00754_row11_col5\" class=\"data row11 col5\" >0.0314</td>\n",
       "      <td id=\"T_00754_row11_col6\" class=\"data row11 col6\" >0.0314</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f686cb74cd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2024-01-21 05:59:00,653] Searching the best hyperparameters using 5600 samples...\n",
      "[I 2024-01-21 06:01:46,527] Finished hyperparameter search!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n"
     ]
    }
   ],
   "source": [
    "tuned_model = exp.tune_model(\n",
    "    best,\n",
    "    search_library=\"optuna\",\n",
    "    choose_better=True,\n",
    "    optimize=\"Accuracy\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       "</style>\n",
       "<table id=\"T_749d3\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th class=\"blank level0\" >&nbsp;</th>\n",
       "      <th id=\"T_749d3_level0_col0\" class=\"col_heading level0 col0\" >Model</th>\n",
       "      <th id=\"T_749d3_level0_col1\" class=\"col_heading level0 col1\" >Accuracy</th>\n",
       "      <th id=\"T_749d3_level0_col2\" class=\"col_heading level0 col2\" >AUC</th>\n",
       "      <th id=\"T_749d3_level0_col3\" class=\"col_heading level0 col3\" >Recall</th>\n",
       "      <th id=\"T_749d3_level0_col4\" class=\"col_heading level0 col4\" >Prec.</th>\n",
       "      <th id=\"T_749d3_level0_col5\" class=\"col_heading level0 col5\" >F1</th>\n",
       "      <th id=\"T_749d3_level0_col6\" class=\"col_heading level0 col6\" >Kappa</th>\n",
       "      <th id=\"T_749d3_level0_col7\" class=\"col_heading level0 col7\" >MCC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th id=\"T_749d3_level0_row0\" class=\"row_heading level0 row0\" >0</th>\n",
       "      <td id=\"T_749d3_row0_col0\" class=\"data row0 col0\" >CatBoost Classifier</td>\n",
       "      <td id=\"T_749d3_row0_col1\" class=\"data row0 col1\" >0.7958</td>\n",
       "      <td id=\"T_749d3_row0_col2\" class=\"data row0 col2\" >0.8737</td>\n",
       "      <td id=\"T_749d3_row0_col3\" class=\"data row0 col3\" >0.8093</td>\n",
       "      <td id=\"T_749d3_row0_col4\" class=\"data row0 col4\" >0.7828</td>\n",
       "      <td id=\"T_749d3_row0_col5\" class=\"data row0 col5\" >0.7958</td>\n",
       "      <td id=\"T_749d3_row0_col6\" class=\"data row0 col6\" >0.5918</td>\n",
       "      <td id=\"T_749d3_row0_col7\" class=\"data row0 col7\" >0.5921</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f68558068c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueTotalExperience</th>\n",
       "      <th>blueHerald</th>\n",
       "      <th>blueKills_win_mean_diff</th>\n",
       "      <th>blueKills_lose_mean_diff</th>\n",
       "      <th>blueDeaths_win_mean_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>blueTotalExperience_blueDragons_mean</th>\n",
       "      <th>blueTotalExperience_blueDragons_max</th>\n",
       "      <th>blueTotalExperience_blueDragons_min</th>\n",
       "      <th>blueTotalExperience_blueDragons_median</th>\n",
       "      <th>blueTotalExperience_blueDragons_q25</th>\n",
       "      <th>blueTotalExperience_blueDragons_q75</th>\n",
       "      <th>blueTotalExperience_blueDragons_std</th>\n",
       "      <th>blueWins</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-6.930097</td>\n",
       "      <td>-6.930097</td>\n",
       "      <td>2.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>933</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>353</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-1.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3469</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2755</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2411</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>16961.0</td>\n",
       "      <td>18472.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>0.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6017</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>20619.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>4.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4257</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>6.715302</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.9842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6028</th>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>19558.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2.069903</td>\n",
       "      <td>2.069903</td>\n",
       "      <td>-0.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2947</th>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>18513.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>-1.284698</td>\n",
       "      <td>...</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2400 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      blueFirstBlood  blueKills  blueDeaths  blueDragons  blueTotalGold  \\\n",
       "4192               0          0           8            0        17409.0   \n",
       "933                0          6           6            0        20619.0   \n",
       "353                0          4           4            0        18117.0   \n",
       "3469               0          7           6            0        18117.0   \n",
       "2755               0          5           6            0        17409.0   \n",
       "...              ...        ...         ...          ...            ...   \n",
       "2411               0          5           6            1        16961.0   \n",
       "6017               0          6          10            0        20619.0   \n",
       "4257               0          4          12            0        17409.0   \n",
       "6028               1          9           5            1        19558.0   \n",
       "2947               1          7           4            0        18513.0   \n",
       "\n",
       "      blueTotalExperience  blueHerald  blueKills_win_mean_diff  \\\n",
       "4192              17256.0           0                -6.930097   \n",
       "933               17256.0           0                -0.930097   \n",
       "353               18201.0           0                -2.930097   \n",
       "3469              18491.0           0                 0.069903   \n",
       "2755              17256.0           0                -1.930097   \n",
       "...                   ...         ...                      ...   \n",
       "2411              18472.0           0                -1.930097   \n",
       "6017              17256.0           1                -0.930097   \n",
       "4257              17256.0           0                -2.930097   \n",
       "6028              18201.0           0                 2.069903   \n",
       "2947              18201.0           1                 0.069903   \n",
       "\n",
       "      blueKills_lose_mean_diff  blueDeaths_win_mean_diff  ...  \\\n",
       "4192                 -6.930097                  2.715302  ...   \n",
       "933                  -0.930097                  0.715302  ...   \n",
       "353                  -2.930097                 -1.284698  ...   \n",
       "3469                  0.069903                  0.715302  ...   \n",
       "2755                 -1.930097                  0.715302  ...   \n",
       "...                        ...                       ...  ...   \n",
       "2411                 -1.930097                  0.715302  ...   \n",
       "6017                 -0.930097                  4.715302  ...   \n",
       "4257                 -2.930097                  6.715302  ...   \n",
       "6028                  2.069903                 -0.284698  ...   \n",
       "2947                  0.069903                 -1.284698  ...   \n",
       "\n",
       "      blueTotalExperience_blueDragons_mean  \\\n",
       "4192                          17820.650391   \n",
       "933                           17820.650391   \n",
       "353                           17820.650391   \n",
       "3469                          17820.650391   \n",
       "2755                          17820.650391   \n",
       "...                                    ...   \n",
       "2411                          18285.949219   \n",
       "6017                          17820.650391   \n",
       "4257                          17820.650391   \n",
       "6028                          18285.949219   \n",
       "2947                          17820.650391   \n",
       "\n",
       "      blueTotalExperience_blueDragons_max  \\\n",
       "4192                              20101.0   \n",
       "933                               20101.0   \n",
       "353                               20101.0   \n",
       "3469                              20101.0   \n",
       "2755                              20101.0   \n",
       "...                                   ...   \n",
       "2411                              20004.0   \n",
       "6017                              20101.0   \n",
       "4257                              20101.0   \n",
       "6028                              20004.0   \n",
       "2947                              20101.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_min  \\\n",
       "4192                              16650.0   \n",
       "933                               16650.0   \n",
       "353                               16650.0   \n",
       "3469                              16650.0   \n",
       "2755                              16650.0   \n",
       "...                                   ...   \n",
       "2411                              16650.0   \n",
       "6017                              16650.0   \n",
       "4257                              16650.0   \n",
       "6028                              16650.0   \n",
       "2947                              16650.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_median  \\\n",
       "4192                                 17256.0   \n",
       "933                                  17256.0   \n",
       "353                                  17256.0   \n",
       "3469                                 17256.0   \n",
       "2755                                 17256.0   \n",
       "...                                      ...   \n",
       "2411                                 18201.0   \n",
       "6017                                 17256.0   \n",
       "4257                                 17256.0   \n",
       "6028                                 18201.0   \n",
       "2947                                 17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q25  \\\n",
       "4192                              17256.0   \n",
       "933                               17256.0   \n",
       "353                               17256.0   \n",
       "3469                              17256.0   \n",
       "2755                              17256.0   \n",
       "...                                   ...   \n",
       "2411                              18021.0   \n",
       "6017                              17256.0   \n",
       "4257                              17256.0   \n",
       "6028                              18021.0   \n",
       "2947                              17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q75  \\\n",
       "4192                              18201.0   \n",
       "933                               18201.0   \n",
       "353                               18201.0   \n",
       "3469                              18201.0   \n",
       "2755                              18201.0   \n",
       "...                                   ...   \n",
       "2411                              18491.0   \n",
       "6017                              18201.0   \n",
       "4257                              18201.0   \n",
       "6028                              18491.0   \n",
       "2947                              18201.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_std  blueWins  prediction_label  \\\n",
       "4192                           807.047668         0                 0   \n",
       "933                            807.047668         0                 0   \n",
       "353                            807.047668         1                 1   \n",
       "3469                           807.047668         1                 1   \n",
       "2755                           807.047668         0                 0   \n",
       "...                                   ...       ...               ...   \n",
       "2411                           596.929260         0                 1   \n",
       "6017                           807.047668         0                 0   \n",
       "4257                           807.047668         0                 0   \n",
       "6028                           596.929260         1                 1   \n",
       "2947                           807.047668         1                 1   \n",
       "\n",
       "      prediction_score  \n",
       "4192            0.9400  \n",
       "933             0.6865  \n",
       "353             0.6821  \n",
       "3469            0.7170  \n",
       "2755            0.9167  \n",
       "...                ...  \n",
       "2411            0.6223  \n",
       "6017            0.8599  \n",
       "4257            0.9842  \n",
       "6028            0.5859  \n",
       "2947            0.8480  \n",
       "\n",
       "[2400 rows x 154 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.predict_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = exp.finalize_model(tuned_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gameId</th>\n",
       "      <th>blueFirstBlood</th>\n",
       "      <th>blueKills</th>\n",
       "      <th>blueDeaths</th>\n",
       "      <th>blueDragons</th>\n",
       "      <th>blueTotalGold</th>\n",
       "      <th>blueTotalExperience</th>\n",
       "      <th>blueHerald</th>\n",
       "      <th>blueKills_win_mean_diff</th>\n",
       "      <th>blueKills_lose_mean_diff</th>\n",
       "      <th>...</th>\n",
       "      <th>blueTotalExperience_blueHerald_std</th>\n",
       "      <th>blueTotalExperience_blueDragons_mean</th>\n",
       "      <th>blueTotalExperience_blueDragons_max</th>\n",
       "      <th>blueTotalExperience_blueDragons_min</th>\n",
       "      <th>blueTotalExperience_blueDragons_median</th>\n",
       "      <th>blueTotalExperience_blueDragons_q25</th>\n",
       "      <th>blueTotalExperience_blueDragons_q75</th>\n",
       "      <th>blueTotalExperience_blueDragons_std</th>\n",
       "      <th>prediction_label</th>\n",
       "      <th>prediction_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>16961.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>18513.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>611.617737</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13475.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>-1.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18472.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.069903</td>\n",
       "      <td>3.069903</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>1</td>\n",
       "      <td>0.5699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>9971</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8368</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>9980</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>17409.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>-2.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>9983</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18513.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>-0.930097</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.8939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>9996</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>18513.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.069903</td>\n",
       "      <td>3.069903</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>18285.949219</td>\n",
       "      <td>20004.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>18021.0</td>\n",
       "      <td>18491.0</td>\n",
       "      <td>596.929260</td>\n",
       "      <td>1</td>\n",
       "      <td>0.7698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>9999</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>18117.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>0.069903</td>\n",
       "      <td>...</td>\n",
       "      <td>796.824707</td>\n",
       "      <td>17820.650391</td>\n",
       "      <td>20101.0</td>\n",
       "      <td>16650.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>17256.0</td>\n",
       "      <td>18201.0</td>\n",
       "      <td>807.047668</td>\n",
       "      <td>0</td>\n",
       "      <td>0.5508</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 154 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      gameId  blueFirstBlood  blueKills  blueDeaths  blueDragons  \\\n",
       "0          9               0          7           6            0   \n",
       "1         15               0          6           6            1   \n",
       "2         18               1          6           4            0   \n",
       "3         23               0          5           4            0   \n",
       "4         31               0         10           8            0   \n",
       "...      ...             ...        ...         ...          ...   \n",
       "1995    9971               0          6           3            0   \n",
       "1996    9980               0          4           4            0   \n",
       "1997    9983               1          6           3            1   \n",
       "1998    9996               1         10           9            1   \n",
       "1999    9999               0          7          11            0   \n",
       "\n",
       "      blueTotalGold  blueTotalExperience  blueHerald  blueKills_win_mean_diff  \\\n",
       "0           16961.0              18201.0           0                 0.069903   \n",
       "1           18513.0              18021.0           1                -0.930097   \n",
       "2           13475.0              17256.0           0                -0.930097   \n",
       "3           17409.0              17256.0           0                -1.930097   \n",
       "4           18117.0              18472.0           0                 3.069903   \n",
       "...             ...                  ...         ...                      ...   \n",
       "1995        17409.0              17256.0           0                -0.930097   \n",
       "1996        17409.0              17256.0           0                -2.930097   \n",
       "1997        18513.0              18201.0           0                -0.930097   \n",
       "1998        18513.0              18201.0           0                 3.069903   \n",
       "1999        18117.0              18201.0           0                 0.069903   \n",
       "\n",
       "      blueKills_lose_mean_diff  ...  blueTotalExperience_blueHerald_std  \\\n",
       "0                     0.069903  ...                          796.824707   \n",
       "1                    -0.930097  ...                          611.617737   \n",
       "2                    -0.930097  ...                          796.824707   \n",
       "3                    -1.930097  ...                          796.824707   \n",
       "4                     3.069903  ...                          796.824707   \n",
       "...                        ...  ...                                 ...   \n",
       "1995                 -0.930097  ...                          796.824707   \n",
       "1996                 -2.930097  ...                          796.824707   \n",
       "1997                 -0.930097  ...                          796.824707   \n",
       "1998                  3.069903  ...                          796.824707   \n",
       "1999                  0.069903  ...                          796.824707   \n",
       "\n",
       "      blueTotalExperience_blueDragons_mean  \\\n",
       "0                             17820.650391   \n",
       "1                             18285.949219   \n",
       "2                             17820.650391   \n",
       "3                             17820.650391   \n",
       "4                             17820.650391   \n",
       "...                                    ...   \n",
       "1995                          17820.650391   \n",
       "1996                          17820.650391   \n",
       "1997                          18285.949219   \n",
       "1998                          18285.949219   \n",
       "1999                          17820.650391   \n",
       "\n",
       "      blueTotalExperience_blueDragons_max  \\\n",
       "0                                 20101.0   \n",
       "1                                 20004.0   \n",
       "2                                 20101.0   \n",
       "3                                 20101.0   \n",
       "4                                 20101.0   \n",
       "...                                   ...   \n",
       "1995                              20101.0   \n",
       "1996                              20101.0   \n",
       "1997                              20004.0   \n",
       "1998                              20004.0   \n",
       "1999                              20101.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_min  \\\n",
       "0                                 16650.0   \n",
       "1                                 16650.0   \n",
       "2                                 16650.0   \n",
       "3                                 16650.0   \n",
       "4                                 16650.0   \n",
       "...                                   ...   \n",
       "1995                              16650.0   \n",
       "1996                              16650.0   \n",
       "1997                              16650.0   \n",
       "1998                              16650.0   \n",
       "1999                              16650.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_median  \\\n",
       "0                                    17256.0   \n",
       "1                                    18201.0   \n",
       "2                                    17256.0   \n",
       "3                                    17256.0   \n",
       "4                                    17256.0   \n",
       "...                                      ...   \n",
       "1995                                 17256.0   \n",
       "1996                                 17256.0   \n",
       "1997                                 18201.0   \n",
       "1998                                 18201.0   \n",
       "1999                                 17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q25  \\\n",
       "0                                 17256.0   \n",
       "1                                 18021.0   \n",
       "2                                 17256.0   \n",
       "3                                 17256.0   \n",
       "4                                 17256.0   \n",
       "...                                   ...   \n",
       "1995                              17256.0   \n",
       "1996                              17256.0   \n",
       "1997                              18021.0   \n",
       "1998                              18021.0   \n",
       "1999                              17256.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_q75  \\\n",
       "0                                 18201.0   \n",
       "1                                 18491.0   \n",
       "2                                 18201.0   \n",
       "3                                 18201.0   \n",
       "4                                 18201.0   \n",
       "...                                   ...   \n",
       "1995                              18201.0   \n",
       "1996                              18201.0   \n",
       "1997                              18491.0   \n",
       "1998                              18491.0   \n",
       "1999                              18201.0   \n",
       "\n",
       "      blueTotalExperience_blueDragons_std  prediction_label  prediction_score  \n",
       "0                              807.047668                 1            0.5946  \n",
       "1                              596.929260                 1            0.7778  \n",
       "2                              807.047668                 0            0.5236  \n",
       "3                              807.047668                 0            0.8852  \n",
       "4                              807.047668                 1            0.5699  \n",
       "...                                   ...               ...               ...  \n",
       "1995                           807.047668                 0            0.8368  \n",
       "1996                           807.047668                 0            0.8880  \n",
       "1997                           596.929260                 1            0.8939  \n",
       "1998                           596.929260                 1            0.7698  \n",
       "1999                           807.047668                 0            0.5508  \n",
       "\n",
       "[2000 rows x 154 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unseen_predictions = exp.predict_model(\n",
    "    final_model, data=test_df.select(pl.exclude(\"blueWins\")).to_pandas()\n",
    ")\n",
    "unseen_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_predictions[[\"gameId\", \"prediction_label\"]].rename(\n",
    "    columns={\"prediction_label\": \"blueWins\"}\n",
    ").to_csv(\"submit.csv\", index=False, header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lightgbm as lgb\n",
    "\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_predict(params, callbacks=[]):\n",
    "    models = []\n",
    "    model_predicts = []\n",
    "    valid_predicts = []\n",
    "\n",
    "    X = train_df.select(pl.exclude([\"gameId\", \"blueWins\"])).to_numpy()\n",
    "    Y = train_df.get_column(\"blueWins\").to_numpy()\n",
    "    for train_indices, valid_indices in kf.split(X):\n",
    "        X_train, Y_train, X_valid, Y_valid = (\n",
    "            X[train_indices],\n",
    "            Y[train_indices],\n",
    "            X[valid_indices],\n",
    "            Y[valid_indices],\n",
    "        )\n",
    "\n",
    "        lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "        lgb_valid = lgb.Dataset(X_valid, Y_valid, reference=lgb_train)\n",
    "\n",
    "        booster = lgb.train(\n",
    "            params,\n",
    "            train_set=lgb_train,\n",
    "            valid_sets=[lgb_train, lgb_valid],\n",
    "            num_boost_round=100000000,\n",
    "            callbacks=[\n",
    "                lgb.early_stopping(100, False, True),\n",
    "                lgb.log_evaluation(100),\n",
    "                *callbacks,\n",
    "            ],\n",
    "        )\n",
    "\n",
    "        models.append(booster)\n",
    "\n",
    "        model_predicts.append(booster.predict(X_valid))\n",
    "        valid_predicts.append(Y_valid)\n",
    "\n",
    "    return models, np.concatenate(model_predicts), np.concatenate(valid_predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.793414\tvalid_1's auc: 0.767369\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's auc: 0.890667\tvalid_1's auc: 0.856319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899352\tvalid_1's auc: 0.878691\n",
      "[200]\ttraining's auc: 0.914717\tvalid_1's auc: 0.88049\n",
      "Early stopping, best iteration is:\n",
      "[161]\ttraining's auc: 0.910056\tvalid_1's auc: 0.880866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.904334\tvalid_1's auc: 0.857239\n",
      "[200]\ttraining's auc: 0.91931\tvalid_1's auc: 0.855936\n",
      "Early stopping, best iteration is:\n",
      "[147]\ttraining's auc: 0.912396\tvalid_1's auc: 0.857664\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.900292\tvalid_1's auc: 0.865369\n",
      "Early stopping, best iteration is:\n",
      "[44]\ttraining's auc: 0.886179\tvalid_1's auc: 0.866551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.900381\tvalid_1's auc: 0.87288\n",
      "Early stopping, best iteration is:\n",
      "[97]\ttraining's auc: 0.899759\tvalid_1's auc: 0.873078\n",
      "Accuracy 0.78225\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 123,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"device\": \"cuda\",\n",
    "}\n",
    "\n",
    "_, predicts, valid = train_and_predict(params)\n",
    "print(\"Accuracy\", accuracy_score(valid, np.rint(predicts)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "\n",
    "params_base = {\n",
    "    \"objective\": \"binary\",\n",
    "    \"metric\": \"auc\",\n",
    "    \"boosting_type\": \"gbdt\",\n",
    "    \"verbosity\": -1,\n",
    "    \"random_state\": 123,\n",
    "    \"learning_rate\": 0.05,\n",
    "    \"device\": \"cuda\",\n",
    "    \"extra_trees\": True,\n",
    "}\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        **params_base,\n",
    "        \"lambda_l1\": trial.suggest_loguniform(\"lambda_l1\", 1e-8, 10.0),\n",
    "        \"lambda_l2\": trial.suggest_loguniform(\"lambda_l2\", 1e-8, 10.0),\n",
    "        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 256),\n",
    "        \"feature_fraction\": trial.suggest_uniform(\"feature_fraction\", 0.4, 1.0),\n",
    "        \"bagging_fraction\": trial.suggest_uniform(\"bagging_fraction\", 0.4, 1.0),\n",
    "        \"bagging_freq\": trial.suggest_int(\"bagging_freq\", 1, 7),\n",
    "        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 5, 100),\n",
    "    }\n",
    "    pruning_callback = optuna.integration.LightGBMPruningCallback(\n",
    "        trial, \"auc\", \"valid_1\"\n",
    "    )\n",
    "    models, predicts, valid_y = train_and_predict(params, callbacks=[pruning_callback])\n",
    "    accuracy = accuracy_score(valid_y, np.rint(predicts))\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.866991\tvalid_1's auc: 0.842999\n",
      "[200]\ttraining's auc: 0.889196\tvalid_1's auc: 0.855283\n",
      "[300]\ttraining's auc: 0.895871\tvalid_1's auc: 0.857366\n",
      "[400]\ttraining's auc: 0.901244\tvalid_1's auc: 0.857007\n",
      "Early stopping, best iteration is:\n",
      "[316]\ttraining's auc: 0.896985\tvalid_1's auc: 0.857811\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.873116\tvalid_1's auc: 0.868951\n",
      "[200]\ttraining's auc: 0.886356\tvalid_1's auc: 0.877082\n",
      "[300]\ttraining's auc: 0.893135\tvalid_1's auc: 0.87956\n",
      "[400]\ttraining's auc: 0.898321\tvalid_1's auc: 0.879835\n",
      "[500]\ttraining's auc: 0.901791\tvalid_1's auc: 0.880305\n",
      "[600]\ttraining's auc: 0.904739\tvalid_1's auc: 0.880985\n",
      "[700]\ttraining's auc: 0.907496\tvalid_1's auc: 0.881002\n",
      "Early stopping, best iteration is:\n",
      "[609]\ttraining's auc: 0.904995\tvalid_1's auc: 0.881282\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.87595\tvalid_1's auc: 0.840762\n",
      "[200]\ttraining's auc: 0.890551\tvalid_1's auc: 0.84718\n",
      "[300]\ttraining's auc: 0.897707\tvalid_1's auc: 0.849974\n",
      "[400]\ttraining's auc: 0.901259\tvalid_1's auc: 0.845123\n",
      "Early stopping, best iteration is:\n",
      "[381]\ttraining's auc: 0.901785\tvalid_1's auc: 0.85069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.87544\tvalid_1's auc: 0.86219\n",
      "[200]\ttraining's auc: 0.889582\tvalid_1's auc: 0.867857\n",
      "[300]\ttraining's auc: 0.89682\tvalid_1's auc: 0.869707\n",
      "[400]\ttraining's auc: 0.901471\tvalid_1's auc: 0.869618\n",
      "Early stopping, best iteration is:\n",
      "[320]\ttraining's auc: 0.897845\tvalid_1's auc: 0.870146\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.873594\tvalid_1's auc: 0.86692\n",
      "[200]\ttraining's auc: 0.887812\tvalid_1's auc: 0.872091\n",
      "[300]\ttraining's auc: 0.89515\tvalid_1's auc: 0.872044\n",
      "[400]\ttraining's auc: 0.900146\tvalid_1's auc: 0.871619\n",
      "Early stopping, best iteration is:\n",
      "[363]\ttraining's auc: 0.898401\tvalid_1's auc: 0.872754\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.938451\tvalid_1's auc: 0.832214\n",
      "Early stopping, best iteration is:\n",
      "[19]\ttraining's auc: 0.902765\tvalid_1's auc: 0.840236\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.939782\tvalid_1's auc: 0.8672\n",
      "Early stopping, best iteration is:\n",
      "[70]\ttraining's auc: 0.928428\tvalid_1's auc: 0.867911\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.942272\tvalid_1's auc: 0.842457\n",
      "Early stopping, best iteration is:\n",
      "[75]\ttraining's auc: 0.933572\tvalid_1's auc: 0.84424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.937367\tvalid_1's auc: 0.861224\n",
      "Early stopping, best iteration is:\n",
      "[84]\ttraining's auc: 0.930241\tvalid_1's auc: 0.861753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.94175\tvalid_1's auc: 0.861924\n",
      "Early stopping, best iteration is:\n",
      "[50]\ttraining's auc: 0.92121\tvalid_1's auc: 0.864172\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.869223\tvalid_1's auc: 0.852166\n",
      "[200]\ttraining's auc: 0.882272\tvalid_1's auc: 0.856594\n",
      "[300]\ttraining's auc: 0.889681\tvalid_1's auc: 0.857084\n",
      "Early stopping, best iteration is:\n",
      "[292]\ttraining's auc: 0.889234\tvalid_1's auc: 0.857527\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.865859\tvalid_1's auc: 0.863222\n",
      "[200]\ttraining's auc: 0.878271\tvalid_1's auc: 0.871271\n",
      "[300]\ttraining's auc: 0.885084\tvalid_1's auc: 0.873927\n",
      "[400]\ttraining's auc: 0.890171\tvalid_1's auc: 0.875157\n",
      "[500]\ttraining's auc: 0.893523\tvalid_1's auc: 0.875588\n",
      "[600]\ttraining's auc: 0.896403\tvalid_1's auc: 0.876374\n",
      "Early stopping, best iteration is:\n",
      "[518]\ttraining's auc: 0.894303\tvalid_1's auc: 0.876538\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.869378\tvalid_1's auc: 0.835886\n",
      "[200]\ttraining's auc: 0.883029\tvalid_1's auc: 0.843406\n",
      "[300]\ttraining's auc: 0.890509\tvalid_1's auc: 0.84641\n",
      "[400]\ttraining's auc: 0.887394\tvalid_1's auc: 0.841073\n",
      "Early stopping, best iteration is:\n",
      "[360]\ttraining's auc: 0.893445\tvalid_1's auc: 0.847944\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.868173\tvalid_1's auc: 0.856523\n",
      "[200]\ttraining's auc: 0.881266\tvalid_1's auc: 0.861952\n",
      "[300]\ttraining's auc: 0.888837\tvalid_1's auc: 0.863869\n",
      "[400]\ttraining's auc: 0.894247\tvalid_1's auc: 0.865979\n",
      "[500]\ttraining's auc: 0.897455\tvalid_1's auc: 0.865804\n",
      "[600]\ttraining's auc: 0.899656\tvalid_1's auc: 0.866735\n",
      "[700]\ttraining's auc: 0.901854\tvalid_1's auc: 0.867237\n",
      "Early stopping, best iteration is:\n",
      "[661]\ttraining's auc: 0.901093\tvalid_1's auc: 0.868056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.865728\tvalid_1's auc: 0.864801\n",
      "[200]\ttraining's auc: 0.879116\tvalid_1's auc: 0.870301\n",
      "[300]\ttraining's auc: 0.886568\tvalid_1's auc: 0.872296\n",
      "[400]\ttraining's auc: 0.891703\tvalid_1's auc: 0.872615\n",
      "Early stopping, best iteration is:\n",
      "[324]\ttraining's auc: 0.88786\tvalid_1's auc: 0.873532\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.784344\tvalid_1's auc: 0.774385\n",
      "Early stopping, best iteration is:\n",
      "[6]\ttraining's auc: 0.850916\tvalid_1's auc: 0.842473\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.881436\tvalid_1's auc: 0.872722\n",
      "[200]\ttraining's auc: 0.894385\tvalid_1's auc: 0.877185\n",
      "[300]\ttraining's auc: 0.901598\tvalid_1's auc: 0.878163\n",
      "[400]\ttraining's auc: 0.90657\tvalid_1's auc: 0.878102\n",
      "Early stopping, best iteration is:\n",
      "[354]\ttraining's auc: 0.904416\tvalid_1's auc: 0.878862\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886044\tvalid_1's auc: 0.844475\n",
      "[200]\ttraining's auc: 0.899582\tvalid_1's auc: 0.849867\n",
      "[300]\ttraining's auc: 0.906562\tvalid_1's auc: 0.851243\n",
      "Early stopping, best iteration is:\n",
      "[288]\ttraining's auc: 0.906022\tvalid_1's auc: 0.851551\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.855683\tvalid_1's auc: 0.827294\n",
      "[200]\ttraining's auc: 0.892234\tvalid_1's auc: 0.860799\n",
      "Early stopping, best iteration is:\n",
      "[176]\ttraining's auc: 0.891372\tvalid_1's auc: 0.86264\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.881775\tvalid_1's auc: 0.867637\n",
      "[200]\ttraining's auc: 0.89676\tvalid_1's auc: 0.870281\n",
      "[300]\ttraining's auc: 0.904427\tvalid_1's auc: 0.869839\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's auc: 0.899129\tvalid_1's auc: 0.871073\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.880567\tvalid_1's auc: 0.854576\n",
      "[200]\ttraining's auc: 0.895649\tvalid_1's auc: 0.857111\n",
      "Early stopping, best iteration is:\n",
      "[155]\ttraining's auc: 0.890292\tvalid_1's auc: 0.857476\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.875908\tvalid_1's auc: 0.868656\n",
      "[200]\ttraining's auc: 0.89151\tvalid_1's auc: 0.875509\n",
      "[300]\ttraining's auc: 0.899098\tvalid_1's auc: 0.875694\n",
      "[400]\ttraining's auc: 0.904402\tvalid_1's auc: 0.877572\n",
      "[500]\ttraining's auc: 0.908013\tvalid_1's auc: 0.877028\n",
      "Early stopping, best iteration is:\n",
      "[428]\ttraining's auc: 0.905262\tvalid_1's auc: 0.877976\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.881909\tvalid_1's auc: 0.843616\n",
      "[200]\ttraining's auc: 0.896657\tvalid_1's auc: 0.847223\n",
      "[300]\ttraining's auc: 0.902635\tvalid_1's auc: 0.843149\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's auc: 0.900553\tvalid_1's auc: 0.848433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.879097\tvalid_1's auc: 0.862206\n",
      "[200]\ttraining's auc: 0.894476\tvalid_1's auc: 0.866716\n",
      "[300]\ttraining's auc: 0.90241\tvalid_1's auc: 0.867022\n",
      "Early stopping, best iteration is:\n",
      "[278]\ttraining's auc: 0.900937\tvalid_1's auc: 0.867192\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.877341\tvalid_1's auc: 0.867786\n",
      "[200]\ttraining's auc: 0.893167\tvalid_1's auc: 0.87116\n",
      "[300]\ttraining's auc: 0.901387\tvalid_1's auc: 0.871641\n",
      "Early stopping, best iteration is:\n",
      "[223]\ttraining's auc: 0.895689\tvalid_1's auc: 0.872485\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890324\tvalid_1's auc: 0.853952\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.874398\tvalid_1's auc: 0.854396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891381\tvalid_1's auc: 0.85612\n",
      "[200]\ttraining's auc: 0.839411\tvalid_1's auc: 0.797557\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's auc: 0.89381\tvalid_1's auc: 0.857479\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888229\tvalid_1's auc: 0.873502\n",
      "[200]\ttraining's auc: 0.903833\tvalid_1's auc: 0.87764\n",
      "[300]\ttraining's auc: 0.912563\tvalid_1's auc: 0.876622\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's auc: 0.907097\tvalid_1's auc: 0.877885\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893171\tvalid_1's auc: 0.846054\n",
      "[200]\ttraining's auc: 0.908678\tvalid_1's auc: 0.848468\n",
      "[300]\ttraining's auc: 0.917676\tvalid_1's auc: 0.848972\n",
      "[400]\ttraining's auc: 0.923615\tvalid_1's auc: 0.848166\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.877779\tvalid_1's auc: 0.852896\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.911535\tvalid_1's auc: 0.851972\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.885321\tvalid_1's auc: 0.855835\n",
      "[200]\ttraining's auc: 0.90133\tvalid_1's auc: 0.857112\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890269\tvalid_1's auc: 0.857986\n",
      "[200]\ttraining's auc: 0.906302\tvalid_1's auc: 0.853844\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's auc: 0.891025\tvalid_1's auc: 0.858512\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.887619\tvalid_1's auc: 0.87454\n",
      "[200]\ttraining's auc: 0.901738\tvalid_1's auc: 0.874016\n",
      "Early stopping, best iteration is:\n",
      "[119]\ttraining's auc: 0.891058\tvalid_1's auc: 0.876071\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892067\tvalid_1's auc: 0.843613\n",
      "[200]\ttraining's auc: 0.90596\tvalid_1's auc: 0.843832\n",
      "[300]\ttraining's auc: 0.915179\tvalid_1's auc: 0.8434\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's auc: 0.911061\tvalid_1's auc: 0.846609\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888363\tvalid_1's auc: 0.862141\n",
      "[200]\ttraining's auc: 0.904416\tvalid_1's auc: 0.863418\n",
      "Early stopping, best iteration is:\n",
      "[165]\ttraining's auc: 0.899942\tvalid_1's auc: 0.865268\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.887699\tvalid_1's auc: 0.870428\n",
      "[200]\ttraining's auc: 0.902707\tvalid_1's auc: 0.866515\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's auc: 0.892209\tvalid_1's auc: 0.870767\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893902\tvalid_1's auc: 0.857647\n",
      "[200]\ttraining's auc: 0.909084\tvalid_1's auc: 0.857646\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's auc: 0.900406\tvalid_1's auc: 0.858753\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.855986\tvalid_1's auc: 0.852989\n",
      "Early stopping, best iteration is:\n",
      "[33]\ttraining's auc: 0.866894\tvalid_1's auc: 0.86333\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896189\tvalid_1's auc: 0.851275\n",
      "[200]\ttraining's auc: 0.910638\tvalid_1's auc: 0.853616\n",
      "Early stopping, best iteration is:\n",
      "[188]\ttraining's auc: 0.909315\tvalid_1's auc: 0.854051\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892659\tvalid_1's auc: 0.86639\n",
      "[200]\ttraining's auc: 0.907737\tvalid_1's auc: 0.86807\n",
      "[300]\ttraining's auc: 0.91591\tvalid_1's auc: 0.866852\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's auc: 0.910275\tvalid_1's auc: 0.868694\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.869788\tvalid_1's auc: 0.855164\n",
      "Early stopping, best iteration is:\n",
      "[30]\ttraining's auc: 0.867449\tvalid_1's auc: 0.86417\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.889083\tvalid_1's auc: 0.856917\n",
      "[200]\ttraining's auc: 0.903754\tvalid_1's auc: 0.856179\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's auc: 0.893279\tvalid_1's auc: 0.858772\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88339\tvalid_1's auc: 0.871969\n",
      "[200]\ttraining's auc: 0.899108\tvalid_1's auc: 0.877987\n",
      "[300]\ttraining's auc: 0.907268\tvalid_1's auc: 0.878883\n",
      "Early stopping, best iteration is:\n",
      "[225]\ttraining's auc: 0.901777\tvalid_1's auc: 0.879105\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.86178\tvalid_1's auc: 0.822564\n",
      "Early stopping, best iteration is:\n",
      "[7]\ttraining's auc: 0.855444\tvalid_1's auc: 0.830731\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886047\tvalid_1's auc: 0.864233\n",
      "[200]\ttraining's auc: 0.902561\tvalid_1's auc: 0.867992\n",
      "[300]\ttraining's auc: 0.910764\tvalid_1's auc: 0.86767\n",
      "Early stopping, best iteration is:\n",
      "[249]\ttraining's auc: 0.90729\tvalid_1's auc: 0.86866\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.885996\tvalid_1's auc: 0.870834\n",
      "[200]\ttraining's auc: 0.901711\tvalid_1's auc: 0.871411\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's auc: 0.890536\tvalid_1's auc: 0.872319\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886129\tvalid_1's auc: 0.857306\n",
      "[200]\ttraining's auc: 0.901343\tvalid_1's auc: 0.855484\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's auc: 0.889038\tvalid_1's auc: 0.858548\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.881833\tvalid_1's auc: 0.871376\n",
      "[200]\ttraining's auc: 0.896094\tvalid_1's auc: 0.877254\n",
      "[300]\ttraining's auc: 0.904206\tvalid_1's auc: 0.878832\n",
      "[400]\ttraining's auc: 0.909612\tvalid_1's auc: 0.87771\n",
      "Early stopping, best iteration is:\n",
      "[350]\ttraining's auc: 0.906952\tvalid_1's auc: 0.879515\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886192\tvalid_1's auc: 0.843579\n",
      "[200]\ttraining's auc: 0.901668\tvalid_1's auc: 0.848554\n",
      "[300]\ttraining's auc: 0.909636\tvalid_1's auc: 0.849424\n",
      "Early stopping, best iteration is:\n",
      "[279]\ttraining's auc: 0.90824\tvalid_1's auc: 0.849996\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88312\tvalid_1's auc: 0.861952\n",
      "[200]\ttraining's auc: 0.898645\tvalid_1's auc: 0.86539\n",
      "Early stopping, best iteration is:\n",
      "[196]\ttraining's auc: 0.898194\tvalid_1's auc: 0.865541\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.882664\tvalid_1's auc: 0.867285\n",
      "[200]\ttraining's auc: 0.898263\tvalid_1's auc: 0.870099\n",
      "Early stopping, best iteration is:\n",
      "[166]\ttraining's auc: 0.894372\tvalid_1's auc: 0.870899\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892881\tvalid_1's auc: 0.855958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.897768\tvalid_1's auc: 0.855839\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.895098\tvalid_1's auc: 0.857673\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88898\tvalid_1's auc: 0.856619\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886336\tvalid_1's auc: 0.857419\n",
      "[200]\ttraining's auc: 0.901426\tvalid_1's auc: 0.858547\n",
      "Early stopping, best iteration is:\n",
      "[154]\ttraining's auc: 0.896264\tvalid_1's auc: 0.859649\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.880525\tvalid_1's auc: 0.870188\n",
      "[200]\ttraining's auc: 0.896434\tvalid_1's auc: 0.876163\n",
      "[300]\ttraining's auc: 0.905603\tvalid_1's auc: 0.878477\n",
      "Early stopping, best iteration is:\n",
      "[289]\ttraining's auc: 0.905231\tvalid_1's auc: 0.879043\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.885639\tvalid_1's auc: 0.844226\n",
      "[200]\ttraining's auc: 0.902127\tvalid_1's auc: 0.848564\n",
      "[300]\ttraining's auc: 0.910715\tvalid_1's auc: 0.850467\n",
      "[400]\ttraining's auc: 0.916291\tvalid_1's auc: 0.850365\n",
      "Early stopping, best iteration is:\n",
      "[357]\ttraining's auc: 0.914119\tvalid_1's auc: 0.851056\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.884374\tvalid_1's auc: 0.864319\n",
      "[200]\ttraining's auc: 0.900011\tvalid_1's auc: 0.867372\n",
      "[300]\ttraining's auc: 0.908648\tvalid_1's auc: 0.867716\n",
      "Early stopping, best iteration is:\n",
      "[259]\ttraining's auc: 0.905633\tvalid_1's auc: 0.868799\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.881428\tvalid_1's auc: 0.867258\n",
      "[200]\ttraining's auc: 0.898047\tvalid_1's auc: 0.870264\n",
      "Early stopping, best iteration is:\n",
      "[181]\ttraining's auc: 0.895771\tvalid_1's auc: 0.870397\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.900638\tvalid_1's auc: 0.855698\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88858\tvalid_1's auc: 0.85652\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89107\tvalid_1's auc: 0.857678\n",
      "[200]\ttraining's auc: 0.906918\tvalid_1's auc: 0.858205\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.895584\tvalid_1's auc: 0.859193\n",
      "[200]\ttraining's auc: 0.911013\tvalid_1's auc: 0.858556\n",
      "Early stopping, best iteration is:\n",
      "[102]\ttraining's auc: 0.896027\tvalid_1's auc: 0.859424\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.884625\tvalid_1's auc: 0.869221\n",
      "[200]\ttraining's auc: 0.905779\tvalid_1's auc: 0.877271\n",
      "[300]\ttraining's auc: 0.914214\tvalid_1's auc: 0.877132\n",
      "[400]\ttraining's auc: 0.818597\tvalid_1's auc: 0.79014\n",
      "Early stopping, best iteration is:\n",
      "[347]\ttraining's auc: 0.917327\tvalid_1's auc: 0.87868\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.897187\tvalid_1's auc: 0.849369\n",
      "[200]\ttraining's auc: 0.91242\tvalid_1's auc: 0.852659\n",
      "[300]\ttraining's auc: 0.921328\tvalid_1's auc: 0.851491\n",
      "Early stopping, best iteration is:\n",
      "[210]\ttraining's auc: 0.913429\tvalid_1's auc: 0.852881\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894382\tvalid_1's auc: 0.867317\n",
      "[200]\ttraining's auc: 0.910064\tvalid_1's auc: 0.869085\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's auc: 0.903888\tvalid_1's auc: 0.869488\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815332\tvalid_1's auc: 0.796583\n",
      "Early stopping, best iteration is:\n",
      "[8]\ttraining's auc: 0.861595\tvalid_1's auc: 0.862958\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891055\tvalid_1's auc: 0.858728\n",
      "[200]\ttraining's auc: 0.9065\tvalid_1's auc: 0.859287\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892512\tvalid_1's auc: 0.857978\n",
      "[200]\ttraining's auc: 0.908547\tvalid_1's auc: 0.855734\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's auc: 0.89663\tvalid_1's auc: 0.859456\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888865\tvalid_1's auc: 0.874479\n",
      "[200]\ttraining's auc: 0.904645\tvalid_1's auc: 0.87793\n",
      "[300]\ttraining's auc: 0.913553\tvalid_1's auc: 0.877587\n",
      "Early stopping, best iteration is:\n",
      "[246]\ttraining's auc: 0.909251\tvalid_1's auc: 0.878863\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894881\tvalid_1's auc: 0.847643\n",
      "[200]\ttraining's auc: 0.910273\tvalid_1's auc: 0.85095\n",
      "[300]\ttraining's auc: 0.918872\tvalid_1's auc: 0.85092\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's auc: 0.914009\tvalid_1's auc: 0.851156\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891045\tvalid_1's auc: 0.864285\n",
      "[200]\ttraining's auc: 0.908148\tvalid_1's auc: 0.866958\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's auc: 0.907586\tvalid_1's auc: 0.867664\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890589\tvalid_1's auc: 0.872335\n",
      "[200]\ttraining's auc: 0.907096\tvalid_1's auc: 0.870368\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's auc: 0.891486\tvalid_1's auc: 0.872555\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886831\tvalid_1's auc: 0.857862\n",
      "[200]\ttraining's auc: 0.902567\tvalid_1's auc: 0.860285\n",
      "Early stopping, best iteration is:\n",
      "[152]\ttraining's auc: 0.896622\tvalid_1's auc: 0.860645\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.87621\tvalid_1's auc: 0.869024\n",
      "[200]\ttraining's auc: 0.896356\tvalid_1's auc: 0.876822\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893384\tvalid_1's auc: 0.857158\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892632\tvalid_1's auc: 0.857216\n",
      "[200]\ttraining's auc: 0.907879\tvalid_1's auc: 0.85836\n",
      "Early stopping, best iteration is:\n",
      "[133]\ttraining's auc: 0.899102\tvalid_1's auc: 0.859593\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.887104\tvalid_1's auc: 0.873408\n",
      "[200]\ttraining's auc: 0.903883\tvalid_1's auc: 0.878332\n",
      "[300]\ttraining's auc: 0.912335\tvalid_1's auc: 0.876972\n",
      "Early stopping, best iteration is:\n",
      "[215]\ttraining's auc: 0.905583\tvalid_1's auc: 0.87881\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893192\tvalid_1's auc: 0.847891\n",
      "[200]\ttraining's auc: 0.909684\tvalid_1's auc: 0.850482\n",
      "[300]\ttraining's auc: 0.91866\tvalid_1's auc: 0.850917\n",
      "Early stopping, best iteration is:\n",
      "[247]\ttraining's auc: 0.914624\tvalid_1's auc: 0.851116\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890361\tvalid_1's auc: 0.865609\n",
      "[200]\ttraining's auc: 0.906884\tvalid_1's auc: 0.868149\n",
      "Early stopping, best iteration is:\n",
      "[189]\ttraining's auc: 0.905697\tvalid_1's auc: 0.868583\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.887109\tvalid_1's auc: 0.869393\n",
      "[200]\ttraining's auc: 0.905031\tvalid_1's auc: 0.868571\n",
      "Early stopping, best iteration is:\n",
      "[118]\ttraining's auc: 0.892315\tvalid_1's auc: 0.87134\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892772\tvalid_1's auc: 0.857321\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891729\tvalid_1's auc: 0.8579\n",
      "[200]\ttraining's auc: 0.906636\tvalid_1's auc: 0.857485\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's auc: 0.896398\tvalid_1's auc: 0.859272\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.847191\tvalid_1's auc: 0.840622\n",
      "Early stopping, best iteration is:\n",
      "[89]\ttraining's auc: 0.884218\tvalid_1's auc: 0.872483\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892385\tvalid_1's auc: 0.847098\n",
      "[200]\ttraining's auc: 0.908108\tvalid_1's auc: 0.850226\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89918\tvalid_1's auc: 0.858865\n",
      "[200]\ttraining's auc: 0.91587\tvalid_1's auc: 0.857054\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's auc: 0.901503\tvalid_1's auc: 0.859633\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893462\tvalid_1's auc: 0.874077\n",
      "[200]\ttraining's auc: 0.910778\tvalid_1's auc: 0.87766\n",
      "Early stopping, best iteration is:\n",
      "[175]\ttraining's auc: 0.907567\tvalid_1's auc: 0.877988\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899448\tvalid_1's auc: 0.848265\n",
      "[200]\ttraining's auc: 0.916777\tvalid_1's auc: 0.850629\n",
      "[300]\ttraining's auc: 0.926546\tvalid_1's auc: 0.850737\n",
      "Early stopping, best iteration is:\n",
      "[212]\ttraining's auc: 0.918381\tvalid_1's auc: 0.851286\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893695\tvalid_1's auc: 0.8663\n",
      "[200]\ttraining's auc: 0.912554\tvalid_1's auc: 0.868845\n",
      "Early stopping, best iteration is:\n",
      "[195]\ttraining's auc: 0.912023\tvalid_1's auc: 0.869069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894855\tvalid_1's auc: 0.871625\n",
      "[200]\ttraining's auc: 0.912987\tvalid_1's auc: 0.870524\n",
      "Early stopping, best iteration is:\n",
      "[126]\ttraining's auc: 0.901267\tvalid_1's auc: 0.872278\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893996\tvalid_1's auc: 0.858841\n",
      "[200]\ttraining's auc: 0.91084\tvalid_1's auc: 0.858191\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's auc: 0.899746\tvalid_1's auc: 0.859629\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888761\tvalid_1's auc: 0.873349\n",
      "[200]\ttraining's auc: 0.906155\tvalid_1's auc: 0.878869\n",
      "Early stopping, best iteration is:\n",
      "[180]\ttraining's auc: 0.903571\tvalid_1's auc: 0.879262\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.895838\tvalid_1's auc: 0.85019\n",
      "[200]\ttraining's auc: 0.912245\tvalid_1's auc: 0.853289\n",
      "[300]\ttraining's auc: 0.921238\tvalid_1's auc: 0.852163\n",
      "Early stopping, best iteration is:\n",
      "[205]\ttraining's auc: 0.912885\tvalid_1's auc: 0.853449\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891671\tvalid_1's auc: 0.865968\n",
      "[200]\ttraining's auc: 0.9086\tvalid_1's auc: 0.868824\n",
      "Early stopping, best iteration is:\n",
      "[153]\ttraining's auc: 0.902722\tvalid_1's auc: 0.869255\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88892\tvalid_1's auc: 0.871082\n",
      "[200]\ttraining's auc: 0.90677\tvalid_1's auc: 0.869751\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.898791\tvalid_1's auc: 0.871977\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893091\tvalid_1's auc: 0.858006\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896073\tvalid_1's auc: 0.85854\n",
      "[200]\ttraining's auc: 0.913012\tvalid_1's auc: 0.857892\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88741\tvalid_1's auc: 0.857784\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896393\tvalid_1's auc: 0.85878\n",
      "[200]\ttraining's auc: 0.912446\tvalid_1's auc: 0.857012\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's auc: 0.897549\tvalid_1's auc: 0.859646\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890657\tvalid_1's auc: 0.872802\n",
      "[200]\ttraining's auc: 0.908003\tvalid_1's auc: 0.877916\n",
      "[300]\ttraining's auc: 0.917456\tvalid_1's auc: 0.877157\n",
      "Early stopping, best iteration is:\n",
      "[226]\ttraining's auc: 0.911044\tvalid_1's auc: 0.878299\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.896314\tvalid_1's auc: 0.846595\n",
      "[200]\ttraining's auc: 0.913204\tvalid_1's auc: 0.850349\n",
      "[300]\ttraining's auc: 0.921333\tvalid_1's auc: 0.84986\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's auc: 0.915323\tvalid_1's auc: 0.850717\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89379\tvalid_1's auc: 0.867045\n",
      "[200]\ttraining's auc: 0.910686\tvalid_1's auc: 0.869214\n",
      "Early stopping, best iteration is:\n",
      "[187]\ttraining's auc: 0.909222\tvalid_1's auc: 0.869744\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893027\tvalid_1's auc: 0.871172\n",
      "[200]\ttraining's auc: 0.910337\tvalid_1's auc: 0.869726\n",
      "Early stopping, best iteration is:\n",
      "[120]\ttraining's auc: 0.897952\tvalid_1's auc: 0.872054\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.827419\tvalid_1's auc: 0.795092\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.897749\tvalid_1's auc: 0.857988\n",
      "[200]\ttraining's auc: 0.914879\tvalid_1's auc: 0.856214\n",
      "Early stopping, best iteration is:\n",
      "[109]\ttraining's auc: 0.900144\tvalid_1's auc: 0.859259\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.815058\tvalid_1's auc: 0.800237\n",
      "Early stopping, best iteration is:\n",
      "[14]\ttraining's auc: 0.861975\tvalid_1's auc: 0.859604\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899334\tvalid_1's auc: 0.848894\n",
      "[200]\ttraining's auc: 0.916294\tvalid_1's auc: 0.85036\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891687\tvalid_1's auc: 0.858352\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894095\tvalid_1's auc: 0.858644\n",
      "[200]\ttraining's auc: 0.91055\tvalid_1's auc: 0.857864\n",
      "Early stopping, best iteration is:\n",
      "[121]\ttraining's auc: 0.89917\tvalid_1's auc: 0.86044\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890145\tvalid_1's auc: 0.873183\n",
      "[200]\ttraining's auc: 0.90551\tvalid_1's auc: 0.876466\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.898239\tvalid_1's auc: 0.857252\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.88909\tvalid_1's auc: 0.860747\n",
      "[200]\ttraining's auc: 0.904153\tvalid_1's auc: 0.85929\n",
      "Early stopping, best iteration is:\n",
      "[110]\ttraining's auc: 0.891506\tvalid_1's auc: 0.861396\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.884404\tvalid_1's auc: 0.872226\n",
      "[200]\ttraining's auc: 0.899889\tvalid_1's auc: 0.876946\n",
      "[300]\ttraining's auc: 0.908416\tvalid_1's auc: 0.878273\n",
      "[400]\ttraining's auc: 0.914149\tvalid_1's auc: 0.877519\n",
      "Early stopping, best iteration is:\n",
      "[356]\ttraining's auc: 0.912017\tvalid_1's auc: 0.879069\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890173\tvalid_1's auc: 0.846837\n",
      "[200]\ttraining's auc: 0.905569\tvalid_1's auc: 0.851122\n",
      "[300]\ttraining's auc: 0.91434\tvalid_1's auc: 0.851169\n",
      "Early stopping, best iteration is:\n",
      "[251]\ttraining's auc: 0.910618\tvalid_1's auc: 0.852368\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.885975\tvalid_1's auc: 0.865063\n",
      "[200]\ttraining's auc: 0.903009\tvalid_1's auc: 0.868342\n",
      "[300]\ttraining's auc: 0.911541\tvalid_1's auc: 0.867851\n",
      "Early stopping, best iteration is:\n",
      "[218]\ttraining's auc: 0.905112\tvalid_1's auc: 0.868915\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.886074\tvalid_1's auc: 0.870447\n",
      "[200]\ttraining's auc: 0.902265\tvalid_1's auc: 0.870936\n",
      "Early stopping, best iteration is:\n",
      "[136]\ttraining's auc: 0.893528\tvalid_1's auc: 0.871878\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.892252\tvalid_1's auc: 0.859425\n",
      "[200]\ttraining's auc: 0.909068\tvalid_1's auc: 0.857548\n",
      "Early stopping, best iteration is:\n",
      "[105]\ttraining's auc: 0.893401\tvalid_1's auc: 0.859553\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888904\tvalid_1's auc: 0.874027\n",
      "[200]\ttraining's auc: 0.905255\tvalid_1's auc: 0.878463\n",
      "[300]\ttraining's auc: 0.91419\tvalid_1's auc: 0.879221\n",
      "Early stopping, best iteration is:\n",
      "[258]\ttraining's auc: 0.910861\tvalid_1's auc: 0.879433\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.893883\tvalid_1's auc: 0.847644\n",
      "[200]\ttraining's auc: 0.910298\tvalid_1's auc: 0.851757\n",
      "[300]\ttraining's auc: 0.919398\tvalid_1's auc: 0.851416\n",
      "Early stopping, best iteration is:\n",
      "[242]\ttraining's auc: 0.914707\tvalid_1's auc: 0.852341\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89094\tvalid_1's auc: 0.865189\n",
      "[200]\ttraining's auc: 0.907546\tvalid_1's auc: 0.868491\n",
      "[300]\ttraining's auc: 0.916288\tvalid_1's auc: 0.868164\n",
      "Early stopping, best iteration is:\n",
      "[240]\ttraining's auc: 0.911521\tvalid_1's auc: 0.869022\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.890045\tvalid_1's auc: 0.872234\n",
      "[200]\ttraining's auc: 0.907401\tvalid_1's auc: 0.870816\n",
      "Early stopping, best iteration is:\n",
      "[125]\ttraining's auc: 0.896027\tvalid_1's auc: 0.872525\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.895452\tvalid_1's auc: 0.857643\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.888061\tvalid_1's auc: 0.858378\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.894755\tvalid_1's auc: 0.856721\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.89683\tvalid_1's auc: 0.857759\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899268\tvalid_1's auc: 0.857864\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.891392\tvalid_1's auc: 0.859117\n",
      "[200]\ttraining's auc: 0.906592\tvalid_1's auc: 0.857141\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899018\tvalid_1's auc: 0.857653\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n",
      "Training until validation scores don't improve for 100 rounds\n"
     ]
    }
   ],
   "source": [
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'lambda_l1': 0.011546663996419845,\n",
       " 'lambda_l2': 4.2290052251299e-05,\n",
       " 'num_leaves': 213,\n",
       " 'feature_fraction': 0.6729700038393581,\n",
       " 'bagging_fraction': 0.9258891415545929,\n",
       " 'bagging_freq': 4,\n",
       " 'min_child_samples': 69}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = study.best_params\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 100 rounds\n",
      "[100]\ttraining's auc: 0.899046\tvalid_1's auc: 0.857022\n",
      "[200]\ttraining's auc: 0.915147\tvalid_1's auc: 0.854658\n",
      "Early stopping, best iteration is:\n",
      "[104]\ttraining's auc: 0.900325\tvalid_1's auc: 0.857695\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = train_df.select(pl.exclude([\"gameId\", \"blueWins\"])).to_numpy()\n",
    "Y = train_df.get_column(\"blueWins\").to_numpy()\n",
    "\n",
    "X_train, X_valid, Y_train, Y_valid = train_test_split(\n",
    "    X, Y, test_size=0.1, random_state=123, shuffle=True\n",
    ")\n",
    "\n",
    "lgb_train = lgb.Dataset(X_train, Y_train)\n",
    "lgb_valid = lgb.Dataset(X_valid, Y_valid, reference=lgb_train)\n",
    "\n",
    "booster = lgb.train(\n",
    "    params,\n",
    "    train_set=lgb_train,\n",
    "    valid_sets=[lgb_train, lgb_valid],\n",
    "    num_boost_round=100000000,\n",
    "    callbacks=[\n",
    "        lgb.early_stopping(100, False, True),\n",
    "        lgb.log_evaluation(100),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_y_pred = booster.predict(\n",
    "    test_df.select(pl.exclude([\"gameId\", \"blueWins\"])).to_numpy()\n",
    ")\n",
    "\n",
    "test_df.with_columns(pl.Series(name=\"blueWins\", values=np.rint(test_y_pred))).select(\n",
    "    pl.col([\"gameId\", \"blueWins\"]).cast(pl.Int64)\n",
    ").write_csv(\"./submit.csv\", include_header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
